{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "0ff5af47",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from torch import nn\n",
    "from torch.utils.data import DataLoader\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import transformers\n",
    "from transformers import AutoModel\n",
    "import sys\n",
    "import math\n",
    "import seaborn as sb\n",
    "import matplotlib.pyplot as plt\n",
    "import sklearn.metrics as perf\n",
    "from scipy.stats import pearsonr\n",
    "sys.path.insert(0,'..')\n",
    "\n",
    "from utils.preprocessing import load_data\n",
    "from utils.transformer_dataset import ReviewDataset\n",
    "from utils.training import train_text_model, train_text_meta_model, train_meta_model\n",
    "from utils.evaluation import get_cls_perf, get_reg_perf, get_predictions\n",
    "from models.transformer_models import UsefulScoreRegressorTextOnly, UsefulScoreRegressorAllFeat, UsefulScoreRegressorMetaOnly\n",
    "from models.transformer_models import UsefulScoreRegressorLinearBaseline, DrugLinearRegression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "4d8a7cb0",
   "metadata": {},
   "outputs": [],
   "source": [
    "nonTextCols = ['ADHD', 'Acne', 'Anxiety', 'Bipolar Disorde', 'Birth Control',\n",
    "               'Depression', 'Insomnia', 'Obesity', 'Pain', 'Weight Loss', 'ratingNormalized']\n",
    "targetCol = 'usefulCountCappedNormalized'"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a24e59cb",
   "metadata": {},
   "source": [
    "# No usefulCount cap and no year filter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "113dcc9d",
   "metadata": {},
   "outputs": [],
   "source": [
    "train, val = load_data('../data/drugsComTrain_raw.csv')\n",
    "trainset = ReviewDataset(train, 'distilbert-base-uncased', nonTextCols, targetCol)\n",
    "valset = ReviewDataset(val, 'distilbert-base-uncased', nonTextCols, targetCol)\n",
    "train_loader = DataLoader(dataset=trainset, batch_size=8, shuffle=True)\n",
    "val_loader = DataLoader(dataset=valset, batch_size=8, shuffle=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a75337a8",
   "metadata": {},
   "source": [
    "## Train Text-Only and Text-Meta models to compare with Linear Baseline"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "814f056e",
   "metadata": {},
   "source": [
    "#### Neural Meta"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "15cd474e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 0, val loss: inf -> 0.00009060, train loss: 0.00010412\n",
      "Epoch 1, val loss: 0.00009225, train loss: 0.00009068\n",
      "Epoch 2, val loss: 0.00009294, train loss: 0.00009031\n",
      "Epoch 3, val loss: 0.00009060 -> 0.00008901, train loss: 0.00009000\n",
      "Epoch 4, val loss: 0.00009021, train loss: 0.00008984\n"
     ]
    }
   ],
   "source": [
    "model = UsefulScoreRegressorMetaOnly(num_meta_feats=len(nonTextCols))\n",
    "model = model.cuda()\n",
    "criterion = nn.MSELoss()\n",
    "optimizer = torch.optim.Adam(model.parameters())\n",
    "\n",
    "train_meta_model(num_epochs=5, model=model, optimizer=optimizer,\n",
    "                 train_loader=train_loader, val_loader=val_loader,\n",
    "                 criterion=criterion, save_path='../models/Neural_Meta.pt', clip=10000.0,\n",
    "                 classify=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4df5839f",
   "metadata": {},
   "source": [
    "#### Text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "26e7c144",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 0, val loss: inf -> 0.00009937, train loss: 0.00017522\n",
      "Epoch 1, val loss: 0.00010440, train loss: 0.00010534\n",
      "Epoch 2, val loss: 0.00010670, train loss: 0.00010561\n",
      "Epoch 3, val loss: 0.00010261, train loss: 0.00010607\n",
      "Epoch 4, val loss: 0.00014371, train loss: 0.00010637\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-3-3649bd754aac>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m     13\u001b[0m                  \u001b[0mtrain_loader\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mtrain_loader\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mval_loader\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mval_loader\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     14\u001b[0m                  \u001b[0mcriterion\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mcriterion\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0msave_path\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;34m'../models/distilBERT_Frozen_TextOnly_Clip.pt'\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mclip\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m1.0\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 15\u001b[1;33m                  classify=False)\n\u001b[0m",
      "\u001b[1;32m~\\OneDrive\\Documents\\GT\\MSCS\\Fall_2021\\CS7650_NLP\\Final_Project\\DrugReviews\\GitHub\\NLP_Final_Project\\utils\\training.py\u001b[0m in \u001b[0;36mtrain_text_model\u001b[1;34m(num_epochs, model, optimizer, train_loader, val_loader, criterion, save_path, clip, classify)\u001b[0m\n\u001b[0;32m     23\u001b[0m             \u001b[0moutput\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtokens\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mattention_mask\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msqueeze\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     24\u001b[0m             \u001b[0mtrain_loss\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mcriterion\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0moutput\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtarget\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 25\u001b[1;33m             \u001b[0mtot_train_loss\u001b[0m \u001b[1;33m+=\u001b[0m \u001b[0mtrain_loss\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mitem\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     26\u001b[0m             \u001b[0mtot_train_samples\u001b[0m \u001b[1;33m+=\u001b[0m \u001b[0mtokens\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     27\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "encoder = AutoModel.from_pretrained('distilbert-base-uncased', return_dict=True)\n",
    "\n",
    "# Freeze encoder parameters\n",
    "for param in encoder.parameters():\n",
    "    param.requires_grad = False\n",
    "\n",
    "model = UsefulScoreRegressorTextOnly(encoder)\n",
    "model = model.cuda()\n",
    "criterion = nn.MSELoss()\n",
    "optimizer = torch.optim.Adam(model.parameters())\n",
    "\n",
    "train_text_model(num_epochs=5, model=model, optimizer=optimizer,\n",
    "                 train_loader=train_loader, val_loader=val_loader,\n",
    "                 criterion=criterion, save_path='../models/distilBERT_Frozen_TextOnly.pt', clip=1.0,\n",
    "                 classify=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "58e01ef8",
   "metadata": {},
   "source": [
    "#### Text-Meta"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "0a1281f8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 0, val loss: inf -> 0.00009712, train loss: 0.00015047\n",
      "Epoch 1, val loss: 0.00009712 -> 0.00009151, train loss: 0.00009867\n",
      "Epoch 2, val loss: 0.00009151 -> 0.00008863, train loss: 0.00009960\n",
      "Epoch 3, val loss: 0.00009045, train loss: 0.00009989\n",
      "Epoch 4, val loss: 0.00009301, train loss: 0.00009969\n"
     ]
    }
   ],
   "source": [
    "encoder = AutoModel.from_pretrained('distilbert-base-uncased', return_dict=True)\n",
    "\n",
    "# Freeze encoder parameters\n",
    "for param in encoder.parameters():\n",
    "    param.requires_grad = False\n",
    "\n",
    "model = UsefulScoreRegressorAllFeat(encoder, num_meta_feats=len(nonTextCols))\n",
    "model = model.cuda()\n",
    "criterion = nn.MSELoss()\n",
    "optimizer = torch.optim.Adam(model.parameters())\n",
    "\n",
    "train_text_meta_model(num_epochs=5, model=model, optimizer=optimizer,\n",
    "                      train_loader=train_loader, val_loader=val_loader,\n",
    "                      criterion=criterion, save_path='../models/distilBERT_Frozen_TextMeta.pt', clip=1.0,\n",
    "                      classify=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6edc1a15",
   "metadata": {},
   "source": [
    "## Evaluate Text and Text-Meta Models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "9650ce28",
   "metadata": {},
   "outputs": [],
   "source": [
    "train, val = load_data('../data/drugsComTest_raw.csv', year_range=[2008, 2017], usefulCount_range=[0, 10000],\n",
    "                      usefulCount_quantile=None)\n",
    "test = pd.concat((train, val), axis=0)\n",
    "testset = ReviewDataset(test, 'distilbert-base-uncased', nonTextCols, targetCol)\n",
    "test_loader = DataLoader(dataset=testset, batch_size=8, shuffle=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "66aefa43",
   "metadata": {},
   "source": [
    "#### Text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "57965819",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "mae: 0.02106926217675209\n",
      "rmse: 0.03769624978303909\n",
      "r2: 0.16104679665887278\n"
     ]
    }
   ],
   "source": [
    "model = torch.load('../models/distilBERT_Frozen_TextOnly.pt')\n",
    "model = model.cuda()\n",
    "mae, rmse, r2 = get_reg_perf(model=model, loader=test_loader, model_type='text')\n",
    "print(f'mae: {mae}')\n",
    "print(f'rmse: {rmse}')\n",
    "print(f'r2: {r2}')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "988a4936",
   "metadata": {},
   "source": [
    "#### Text-Meta"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "580ca38a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "mae: 0.01857740804553032\n",
      "rmse: 0.03731502220034599\n",
      "r2: 0.17792984195345796\n"
     ]
    }
   ],
   "source": [
    "model = torch.load('../models/distilBERT_Frozen_TextMeta.pt')\n",
    "model = model.cuda()\n",
    "mae, rmse, r2 = get_reg_perf(model=model, loader=test_loader, model_type='text-meta')\n",
    "print(f'mae: {mae}')\n",
    "print(f'rmse: {rmse}')\n",
    "print(f'r2: {r2}')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f82e7f60",
   "metadata": {},
   "source": [
    "# usefulCount cap of 99th percentile and years 2009 to 2013 filter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "260c8204",
   "metadata": {},
   "outputs": [],
   "source": [
    "train, val = load_data('../data/drugsComTrain_raw.csv', year_range=[2009, 2013], usefulCount_quantile=0.99)\n",
    "\n",
    "nonTextCols = ['ADHD', 'Acne', 'Anxiety', 'Bipolar Disorde', 'Birth Control',\n",
    "               'Depression', 'Insomnia', 'Obesity', 'Pain', 'Weight Loss', 'ratingNormalized']\n",
    "targetCol = 'usefulCountCappedNormalized'\n",
    "\n",
    "trainset = ReviewDataset(train, 'distilbert-base-uncased', nonTextCols, targetCol)\n",
    "valset = ReviewDataset(val, 'distilbert-base-uncased', nonTextCols, targetCol)\n",
    "train_loader = DataLoader(dataset=trainset, batch_size=8, shuffle=True)\n",
    "val_loader = DataLoader(dataset=valset, batch_size=8, shuffle=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "56f2da0b",
   "metadata": {},
   "source": [
    "#### Text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "e10292aa",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 0, val loss: inf -> 0.00414581, train loss: 0.00399515\n",
      "Epoch 1, val loss: 0.00414581 -> 0.00360033, train loss: 0.00367326\n",
      "Epoch 2, val loss: 0.00382328, train loss: 0.00356392\n",
      "Epoch 3, val loss: 0.00420140, train loss: 0.00359742\n",
      "Epoch 4, val loss: 0.00371807, train loss: 0.00358709\n",
      "Epoch 5, val loss: 0.00360033 -> 0.00359229, train loss: 0.00357028\n",
      "Epoch 6, val loss: 0.00370034, train loss: 0.00354826\n",
      "Epoch 7, val loss: 0.00362748, train loss: 0.00352941\n",
      "Epoch 8, val loss: 0.00376224, train loss: 0.00354951\n",
      "Epoch 9, val loss: 0.00363325, train loss: 0.00352178\n"
     ]
    }
   ],
   "source": [
    "encoder = AutoModel.from_pretrained('distilbert-base-uncased', return_dict=True)\n",
    "\n",
    "# Freeze encoder parameters\n",
    "for param in encoder.parameters():\n",
    "    param.requires_grad = False\n",
    "\n",
    "model = UsefulScoreRegressorTextOnly(encoder)\n",
    "model = model.cuda()\n",
    "criterion = nn.MSELoss()\n",
    "optimizer = torch.optim.Adam(model.parameters())\n",
    "\n",
    "train_text_model(num_epochs=10, model=model, optimizer=optimizer,\n",
    "                 train_loader=train_loader, val_loader=val_loader,\n",
    "                 criterion=criterion, save_path='../models/distilBERT_Frozen_TextOnly_Cap99_2009-2013.pt', clip=1.0,\n",
    "                 classify=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "67873b1d",
   "metadata": {},
   "source": [
    "#### Text-Meta"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "a31adb1a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 0, val loss: inf -> 0.00493514, train loss: 0.00385133\n",
      "Epoch 1, val loss: 0.00493514 -> 0.00356563, train loss: 0.00343594\n",
      "Epoch 2, val loss: 0.00359935, train loss: 0.00340410\n",
      "Epoch 3, val loss: 0.00356563 -> 0.00353534, train loss: 0.00336819\n",
      "Epoch 4, val loss: 0.00353534 -> 0.00349383, train loss: 0.00332359\n",
      "Epoch 5, val loss: 0.00356059, train loss: 0.00330114\n",
      "Epoch 6, val loss: 0.00352374, train loss: 0.00326937\n",
      "Epoch 7, val loss: 0.00349383 -> 0.00341862, train loss: 0.00325463\n",
      "Epoch 8, val loss: 0.00347905, train loss: 0.00326640\n",
      "Epoch 9, val loss: 0.00349266, train loss: 0.00323893\n"
     ]
    }
   ],
   "source": [
    "encoder = AutoModel.from_pretrained('distilbert-base-uncased', return_dict=True)\n",
    "\n",
    "# Freeze encoder parameters\n",
    "for param in encoder.parameters():\n",
    "    param.requires_grad = False\n",
    "\n",
    "model = UsefulScoreRegressorAllFeat(encoder, num_meta_feats=len(nonTextCols))\n",
    "model = model.cuda()\n",
    "criterion = nn.MSELoss()\n",
    "optimizer = torch.optim.Adam(model.parameters())\n",
    "\n",
    "train_text_meta_model(num_epochs=10, model=model, optimizer=optimizer,\n",
    "                      train_loader=train_loader, val_loader=val_loader,\n",
    "                      criterion=criterion, save_path='../models/distilBERT_Frozen_TextMeta_Cap99_2009-2013.pt', clip=1.0,\n",
    "                      classify=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e5a9d8ae",
   "metadata": {},
   "source": [
    "#### Neural Meta"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "e0e92c32",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 0, val loss: inf -> 0.00377398, train loss: 0.00432316\n",
      "Epoch 1, val loss: 0.00377772, train loss: 0.00350335\n",
      "Epoch 2, val loss: 0.00377398 -> 0.00372690, train loss: 0.00346241\n",
      "Epoch 3, val loss: 0.00372690 -> 0.00371696, train loss: 0.00345475\n",
      "Epoch 4, val loss: 0.00372163, train loss: 0.00342369\n",
      "Epoch 5, val loss: 0.00371696 -> 0.00370639, train loss: 0.00341485\n",
      "Epoch 6, val loss: 0.00371276, train loss: 0.00341115\n",
      "Epoch 7, val loss: 0.00371667, train loss: 0.00338426\n",
      "Epoch 8, val loss: 0.00370639 -> 0.00369019, train loss: 0.00338861\n",
      "Epoch 9, val loss: 0.00369298, train loss: 0.00339327\n"
     ]
    }
   ],
   "source": [
    "model = UsefulScoreRegressorMetaOnly(num_meta_feats=len(nonTextCols))\n",
    "model = model.cuda()\n",
    "criterion = nn.MSELoss()\n",
    "optimizer = torch.optim.Adam(model.parameters())\n",
    "\n",
    "train_meta_model(num_epochs=10, model=model, optimizer=optimizer,\n",
    "                 train_loader=train_loader, val_loader=val_loader,\n",
    "                 criterion=criterion, save_path='../models/Neural_Meta_Cap99_2009-2013.pt', clip=10000.0,\n",
    "                 classify=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3fdcbc61",
   "metadata": {},
   "source": [
    "#### Linear Meta"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "9b108ef7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 0, val loss: inf -> 0.00386727, train loss: 0.00474434\n",
      "Epoch 1, val loss: 0.00386727 -> 0.00379575, train loss: 0.00347593\n",
      "Epoch 2, val loss: 0.00380253, train loss: 0.00344485\n",
      "Epoch 3, val loss: 0.00382117, train loss: 0.00344569\n",
      "Epoch 4, val loss: 0.00379943, train loss: 0.00344794\n",
      "Epoch 5, val loss: 0.00379575 -> 0.00377466, train loss: 0.00344950\n",
      "Epoch 6, val loss: 0.00379991, train loss: 0.00345063\n",
      "Epoch 7, val loss: 0.00378471, train loss: 0.00344849\n",
      "Epoch 8, val loss: 0.00378576, train loss: 0.00344192\n",
      "Epoch 9, val loss: 0.00379063, train loss: 0.00344910\n"
     ]
    }
   ],
   "source": [
    "model = UsefulScoreRegressorLinearBaseline(num_meta_feats=len(nonTextCols))\n",
    "model = model.cuda()\n",
    "criterion = nn.MSELoss()\n",
    "optimizer = torch.optim.Adam(model.parameters())\n",
    "\n",
    "train_meta_model(num_epochs=10, model=model, optimizer=optimizer,\n",
    "                 train_loader=train_loader, val_loader=val_loader,\n",
    "                 criterion=criterion, save_path='../models/Linear_Meta_Cap99_2009-2013.pt', clip=10000.0,\n",
    "                 classify=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ef539ff1",
   "metadata": {},
   "source": [
    "# usefulCount cap of 99th percentile and years 2013 to 2017 with Age Feature"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "4f6976fd",
   "metadata": {},
   "outputs": [],
   "source": [
    "train, val = load_data('../data/drugsComTrain_raw.csv', year_range=[2013, 2017], usefulCount_quantile=0.99)\n",
    "\n",
    "nonTextCols = ['ADHD', 'Acne', 'Anxiety', 'Bipolar Disorde', 'Birth Control',\n",
    "               'Depression', 'Insomnia', 'Obesity', 'Pain', 'Weight Loss', 'ratingNormalized', 'ageScore']\n",
    "targetCol = 'usefulCountCappedNormalized'\n",
    "\n",
    "trainset = ReviewDataset(train, 'distilbert-base-uncased', nonTextCols, targetCol)\n",
    "valset = ReviewDataset(val, 'distilbert-base-uncased', nonTextCols, targetCol)\n",
    "train_loader = DataLoader(dataset=trainset, batch_size=8, shuffle=True)\n",
    "val_loader = DataLoader(dataset=valset, batch_size=8, shuffle=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bac2331a",
   "metadata": {},
   "source": [
    "#### Text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "38c95fa2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 0, val loss: inf -> 0.00320778, train loss: 0.00371177\n",
      "Epoch 1, val loss: 0.00379869, train loss: 0.00342485\n",
      "Epoch 2, val loss: 0.00334750, train loss: 0.00337896\n",
      "Epoch 3, val loss: 0.00327002, train loss: 0.00334159\n",
      "Epoch 4, val loss: 0.00326901, train loss: 0.00334327\n",
      "Epoch 5, val loss: 0.00330397, train loss: 0.00332823\n",
      "Epoch 6, val loss: 0.00320778 -> 0.00314411, train loss: 0.00332504\n",
      "Epoch 7, val loss: 0.00314411 -> 0.00303444, train loss: 0.00329159\n",
      "Epoch 8, val loss: 0.00324357, train loss: 0.00328624\n",
      "Epoch 9, val loss: 0.00345990, train loss: 0.00329043\n"
     ]
    }
   ],
   "source": [
    "encoder = AutoModel.from_pretrained('distilbert-base-uncased', return_dict=True)\n",
    "\n",
    "# Freeze encoder parameters\n",
    "for param in encoder.parameters():\n",
    "    param.requires_grad = False\n",
    "\n",
    "model = UsefulScoreRegressorTextOnly(encoder)\n",
    "model = model.cuda()\n",
    "criterion = nn.MSELoss()\n",
    "optimizer = torch.optim.Adam(model.parameters())\n",
    "\n",
    "train_text_model(num_epochs=10, model=model, optimizer=optimizer,\n",
    "                 train_loader=train_loader, val_loader=val_loader,\n",
    "                 criterion=criterion, save_path='../models/distilBERT_Frozen_TextOnly_Cap99_2013-2017_wAge.pt', clip=1.0,\n",
    "                 classify=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2e0d0519",
   "metadata": {},
   "source": [
    "#### Text-Meta"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "8a963273",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 0, val loss: inf -> 0.00282732, train loss: 0.00295192\n",
      "Epoch 1, val loss: 0.00282732 -> 0.00232343, train loss: 0.00243734\n",
      "Epoch 2, val loss: 0.00244299, train loss: 0.00236318\n",
      "Epoch 3, val loss: 0.00245175, train loss: 0.00232723\n",
      "Epoch 4, val loss: 0.00232343 -> 0.00210326, train loss: 0.00231071\n",
      "Epoch 5, val loss: 0.00222636, train loss: 0.00233250\n",
      "Epoch 6, val loss: 0.00228119, train loss: 0.00227522\n",
      "Epoch 7, val loss: 0.00230737, train loss: 0.00227874\n",
      "Epoch 8, val loss: 0.00210518, train loss: 0.00226679\n",
      "Epoch 9, val loss: 0.00223481, train loss: 0.00224247\n"
     ]
    }
   ],
   "source": [
    "encoder = AutoModel.from_pretrained('distilbert-base-uncased', return_dict=True)\n",
    "\n",
    "# Freeze encoder parameters\n",
    "for param in encoder.parameters():\n",
    "    param.requires_grad = False\n",
    "\n",
    "model = UsefulScoreRegressorAllFeat(encoder, num_meta_feats=len(nonTextCols))\n",
    "model = model.cuda()\n",
    "criterion = nn.MSELoss()\n",
    "optimizer = torch.optim.Adam(model.parameters())\n",
    "\n",
    "train_text_meta_model(num_epochs=10, model=model, optimizer=optimizer,\n",
    "                      train_loader=train_loader, val_loader=val_loader,\n",
    "                      criterion=criterion, save_path='../models/distilBERT_Frozen_TextMeta_Cap99_2013-2017_wAge.pt', clip=1.0,\n",
    "                      classify=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6310d178",
   "metadata": {},
   "source": [
    "### Baselines"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0217d4a6",
   "metadata": {},
   "source": [
    "#### Neural Meta"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "65650b43",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 0, val loss: inf -> 0.00238019, train loss: 0.00263480\n",
      "Epoch 1, val loss: 0.00238019 -> 0.00233620, train loss: 0.00238714\n",
      "Epoch 2, val loss: 0.00235048, train loss: 0.00235544\n",
      "Epoch 3, val loss: 0.00233620 -> 0.00230630, train loss: 0.00231485\n",
      "Epoch 4, val loss: 0.00230630 -> 0.00230355, train loss: 0.00230843\n",
      "Epoch 5, val loss: 0.00232830, train loss: 0.00231691\n",
      "Epoch 6, val loss: 0.00232797, train loss: 0.00230143\n",
      "Epoch 7, val loss: 0.00230355 -> 0.00227928, train loss: 0.00228926\n",
      "Epoch 8, val loss: 0.00227928 -> 0.00227811, train loss: 0.00230391\n",
      "Epoch 9, val loss: 0.00230870, train loss: 0.00230553\n"
     ]
    }
   ],
   "source": [
    "model = UsefulScoreRegressorMetaOnly(num_meta_feats=len(nonTextCols))\n",
    "model = model.cuda()\n",
    "criterion = nn.MSELoss()\n",
    "optimizer = torch.optim.Adam(model.parameters())\n",
    "\n",
    "train_meta_model(num_epochs=10, model=model, optimizer=optimizer,\n",
    "                 train_loader=train_loader, val_loader=val_loader,\n",
    "                 criterion=criterion, save_path='../models/Neural_Meta_Cap99_2013-2017_wAge.pt', clip=10000.0,\n",
    "                 classify=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6cb1fa90",
   "metadata": {},
   "source": [
    "#### Linear Meta"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "8b3b2a4b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 0, val loss: inf -> 0.00265827, train loss: 0.00380742\n",
      "Epoch 1, val loss: 0.00266755, train loss: 0.00258430\n",
      "Epoch 2, val loss: 0.00265827 -> 0.00265808, train loss: 0.00257895\n",
      "Epoch 3, val loss: 0.00265808 -> 0.00265717, train loss: 0.00258296\n",
      "Epoch 4, val loss: 0.00268114, train loss: 0.00258043\n",
      "Epoch 5, val loss: 0.00267778, train loss: 0.00258328\n",
      "Epoch 6, val loss: 0.00266439, train loss: 0.00258127\n",
      "Epoch 7, val loss: 0.00266649, train loss: 0.00258429\n",
      "Epoch 8, val loss: 0.00266351, train loss: 0.00258160\n",
      "Epoch 9, val loss: 0.00265717 -> 0.00265645, train loss: 0.00258386\n"
     ]
    }
   ],
   "source": [
    "model = UsefulScoreRegressorLinearBaseline(num_meta_feats=len(nonTextCols))\n",
    "model = model.cuda()\n",
    "criterion = nn.MSELoss()\n",
    "optimizer = torch.optim.Adam(model.parameters())\n",
    "\n",
    "train_meta_model(num_epochs=10, model=model, optimizer=optimizer,\n",
    "                 train_loader=train_loader, val_loader=val_loader,\n",
    "                 criterion=criterion, save_path='../models/Linear_Meta_Cap99_2013-2017_wAge.pt', clip=10000.0,\n",
    "                 classify=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6bc8ff28",
   "metadata": {},
   "source": [
    "## 2013 to 2017 model no age, to see impact of age"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "99f8c546",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 0, val loss: inf -> 0.00300278, train loss: 0.00328338\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-3-6376044f9414>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m     24\u001b[0m                       \u001b[0mtrain_loader\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mtrain_loader\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mval_loader\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mval_loader\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     25\u001b[0m                       \u001b[0mcriterion\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mcriterion\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0msave_path\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;34m'../models/distilBERT_Frozen_TextMeta_Cap99_2013-2017_NoAge.pt'\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mclip\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m1.0\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 26\u001b[1;33m                       classify=False)\n\u001b[0m",
      "\u001b[1;32m~\\OneDrive\\Documents\\GT\\MSCS\\Fall_2021\\CS7650_NLP\\Final_Project\\DrugReviews\\GitHub\\NLP_Final_Project\\utils\\training.py\u001b[0m in \u001b[0;36mtrain_text_meta_model\u001b[1;34m(num_epochs, model, optimizer, train_loader, val_loader, criterion, save_path, clip, classify)\u001b[0m\n\u001b[0;32m     80\u001b[0m             \u001b[0moutput\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtokens\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mattention_mask\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mnonText\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msqueeze\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     81\u001b[0m             \u001b[0mtrain_loss\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mcriterion\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0moutput\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtarget\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 82\u001b[1;33m             \u001b[0mtot_train_loss\u001b[0m \u001b[1;33m+=\u001b[0m \u001b[0mtrain_loss\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mitem\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     83\u001b[0m             \u001b[0mtot_train_samples\u001b[0m \u001b[1;33m+=\u001b[0m \u001b[0mtokens\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     84\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "train, val = load_data('../data/drugsComTrain_raw.csv', year_range=[2013, 2017], usefulCount_quantile=0.99)\n",
    "\n",
    "nonTextCols = ['ADHD', 'Acne', 'Anxiety', 'Bipolar Disorde', 'Birth Control',\n",
    "               'Depression', 'Insomnia', 'Obesity', 'Pain', 'Weight Loss', 'ratingNormalized']\n",
    "targetCol = 'usefulCountCappedNormalized'\n",
    "\n",
    "trainset = ReviewDataset(train, 'distilbert-base-uncased', nonTextCols, targetCol)\n",
    "valset = ReviewDataset(val, 'distilbert-base-uncased', nonTextCols, targetCol)\n",
    "train_loader = DataLoader(dataset=trainset, batch_size=8, shuffle=True)\n",
    "val_loader = DataLoader(dataset=valset, batch_size=8, shuffle=False)\n",
    "\n",
    "encoder = AutoModel.from_pretrained('distilbert-base-uncased', return_dict=True)\n",
    "\n",
    "# Freeze encoder parameters\n",
    "for param in encoder.parameters():\n",
    "    param.requires_grad = False\n",
    "\n",
    "model = UsefulScoreRegressorAllFeat(encoder, num_meta_feats=len(nonTextCols))\n",
    "model = model.cuda()\n",
    "criterion = nn.MSELoss()\n",
    "optimizer = torch.optim.Adam(model.parameters())\n",
    "\n",
    "train_text_meta_model(num_epochs=10, model=model, optimizer=optimizer,\n",
    "                      train_loader=train_loader, val_loader=val_loader,\n",
    "                      criterion=criterion, save_path='../models/distilBERT_Frozen_TextMeta_Cap99_2013-2017_NoAge.pt', clip=1.0,\n",
    "                      classify=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f3d55c5a",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "nlp",
   "language": "python",
   "name": "nlp"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
