{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "DgfHNcOPbOk3"
      },
      "source": [
        "### A Simplied Interface to Text Classification With Hugging Face Transformers in TensorFlow Using [ktrain](https://github.com/amaiya/ktrain)\n",
        "\n",
        "*ktrain* requires TensorFlow 2."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "BDBNS4iNXuUL",
        "outputId": "16a47c50-b569-4371-d9e5-8c45f5da8f2b"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: tensorflow in /usr/local/lib/python3.7/dist-packages (2.7.0)\n",
            "Requirement already satisfied: absl-py>=0.4.0 in /usr/local/lib/python3.7/dist-packages (from tensorflow) (0.12.0)\n",
            "Requirement already satisfied: google-pasta>=0.1.1 in /usr/local/lib/python3.7/dist-packages (from tensorflow) (0.2.0)\n",
            "Requirement already satisfied: keras-preprocessing>=1.1.1 in /usr/local/lib/python3.7/dist-packages (from tensorflow) (1.1.2)\n",
            "Requirement already satisfied: flatbuffers<3.0,>=1.12 in /usr/local/lib/python3.7/dist-packages (from tensorflow) (2.0)\n",
            "Requirement already satisfied: tensorflow-io-gcs-filesystem>=0.21.0 in /usr/local/lib/python3.7/dist-packages (from tensorflow) (0.22.0)\n",
            "Requirement already satisfied: tensorflow-estimator<2.8,~=2.7.0rc0 in /usr/local/lib/python3.7/dist-packages (from tensorflow) (2.7.0)\n",
            "Requirement already satisfied: numpy>=1.14.5 in /usr/local/lib/python3.7/dist-packages (from tensorflow) (1.19.5)\n",
            "Requirement already satisfied: gast<0.5.0,>=0.2.1 in /usr/local/lib/python3.7/dist-packages (from tensorflow) (0.4.0)\n",
            "Requirement already satisfied: wrapt>=1.11.0 in /usr/local/lib/python3.7/dist-packages (from tensorflow) (1.13.3)\n",
            "Requirement already satisfied: six>=1.12.0 in /usr/local/lib/python3.7/dist-packages (from tensorflow) (1.15.0)\n",
            "Requirement already satisfied: protobuf>=3.9.2 in /usr/local/lib/python3.7/dist-packages (from tensorflow) (3.17.3)\n",
            "Requirement already satisfied: typing-extensions>=3.6.6 in /usr/local/lib/python3.7/dist-packages (from tensorflow) (3.10.0.2)\n",
            "Requirement already satisfied: wheel<1.0,>=0.32.0 in /usr/local/lib/python3.7/dist-packages (from tensorflow) (0.37.0)\n",
            "Requirement already satisfied: keras<2.8,>=2.7.0rc0 in /usr/local/lib/python3.7/dist-packages (from tensorflow) (2.7.0)\n",
            "Requirement already satisfied: astunparse>=1.6.0 in /usr/local/lib/python3.7/dist-packages (from tensorflow) (1.6.3)\n",
            "Requirement already satisfied: opt-einsum>=2.3.2 in /usr/local/lib/python3.7/dist-packages (from tensorflow) (3.3.0)\n",
            "Requirement already satisfied: h5py>=2.9.0 in /usr/local/lib/python3.7/dist-packages (from tensorflow) (3.1.0)\n",
            "Requirement already satisfied: libclang>=9.0.1 in /usr/local/lib/python3.7/dist-packages (from tensorflow) (12.0.0)\n",
            "Requirement already satisfied: grpcio<2.0,>=1.24.3 in /usr/local/lib/python3.7/dist-packages (from tensorflow) (1.42.0)\n",
            "Requirement already satisfied: termcolor>=1.1.0 in /usr/local/lib/python3.7/dist-packages (from tensorflow) (1.1.0)\n",
            "Requirement already satisfied: tensorboard~=2.6 in /usr/local/lib/python3.7/dist-packages (from tensorflow) (2.7.0)\n",
            "Requirement already satisfied: cached-property in /usr/local/lib/python3.7/dist-packages (from h5py>=2.9.0->tensorflow) (1.5.2)\n",
            "Requirement already satisfied: tensorboard-data-server<0.7.0,>=0.6.0 in /usr/local/lib/python3.7/dist-packages (from tensorboard~=2.6->tensorflow) (0.6.1)\n",
            "Requirement already satisfied: werkzeug>=0.11.15 in /usr/local/lib/python3.7/dist-packages (from tensorboard~=2.6->tensorflow) (1.0.1)\n",
            "Requirement already satisfied: requests<3,>=2.21.0 in /usr/local/lib/python3.7/dist-packages (from tensorboard~=2.6->tensorflow) (2.23.0)\n",
            "Requirement already satisfied: markdown>=2.6.8 in /usr/local/lib/python3.7/dist-packages (from tensorboard~=2.6->tensorflow) (3.3.6)\n",
            "Requirement already satisfied: setuptools>=41.0.0 in /usr/local/lib/python3.7/dist-packages (from tensorboard~=2.6->tensorflow) (57.4.0)\n",
            "Requirement already satisfied: tensorboard-plugin-wit>=1.6.0 in /usr/local/lib/python3.7/dist-packages (from tensorboard~=2.6->tensorflow) (1.8.0)\n",
            "Requirement already satisfied: google-auth<3,>=1.6.3 in /usr/local/lib/python3.7/dist-packages (from tensorboard~=2.6->tensorflow) (1.35.0)\n",
            "Requirement already satisfied: google-auth-oauthlib<0.5,>=0.4.1 in /usr/local/lib/python3.7/dist-packages (from tensorboard~=2.6->tensorflow) (0.4.6)\n",
            "Requirement already satisfied: pyasn1-modules>=0.2.1 in /usr/local/lib/python3.7/dist-packages (from google-auth<3,>=1.6.3->tensorboard~=2.6->tensorflow) (0.2.8)\n",
            "Requirement already satisfied: rsa<5,>=3.1.4 in /usr/local/lib/python3.7/dist-packages (from google-auth<3,>=1.6.3->tensorboard~=2.6->tensorflow) (4.8)\n",
            "Requirement already satisfied: cachetools<5.0,>=2.0.0 in /usr/local/lib/python3.7/dist-packages (from google-auth<3,>=1.6.3->tensorboard~=2.6->tensorflow) (4.2.4)\n",
            "Requirement already satisfied: requests-oauthlib>=0.7.0 in /usr/local/lib/python3.7/dist-packages (from google-auth-oauthlib<0.5,>=0.4.1->tensorboard~=2.6->tensorflow) (1.3.0)\n",
            "Requirement already satisfied: importlib-metadata>=4.4 in /usr/local/lib/python3.7/dist-packages (from markdown>=2.6.8->tensorboard~=2.6->tensorflow) (4.8.2)\n",
            "Requirement already satisfied: zipp>=0.5 in /usr/local/lib/python3.7/dist-packages (from importlib-metadata>=4.4->markdown>=2.6.8->tensorboard~=2.6->tensorflow) (3.6.0)\n",
            "Requirement already satisfied: pyasn1<0.5.0,>=0.4.6 in /usr/local/lib/python3.7/dist-packages (from pyasn1-modules>=0.2.1->google-auth<3,>=1.6.3->tensorboard~=2.6->tensorflow) (0.4.8)\n",
            "Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.7/dist-packages (from requests<3,>=2.21.0->tensorboard~=2.6->tensorflow) (1.24.3)\n",
            "Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.7/dist-packages (from requests<3,>=2.21.0->tensorboard~=2.6->tensorflow) (2.10)\n",
            "Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.7/dist-packages (from requests<3,>=2.21.0->tensorboard~=2.6->tensorflow) (3.0.4)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.7/dist-packages (from requests<3,>=2.21.0->tensorboard~=2.6->tensorflow) (2021.10.8)\n",
            "Requirement already satisfied: oauthlib>=3.0.0 in /usr/local/lib/python3.7/dist-packages (from requests-oauthlib>=0.7.0->google-auth-oauthlib<0.5,>=0.4.1->tensorboard~=2.6->tensorflow) (3.1.1)\n"
          ]
        }
      ],
      "source": [
        "!pip install tensorflow"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "MAA46kq4X0C_",
        "outputId": "937ecf18-6a54-4419-9914-41582e9d5f39"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "2.7.0\n"
          ]
        }
      ],
      "source": [
        "import tensorflow as tf\n",
        "print(tf.__version__)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "iitDk1j6bpY3"
      },
      "source": [
        "We then need to install *ktrain* library using pip."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "sAYBZG2SX4nP"
      },
      "outputs": [],
      "source": [
        "!pip3 install -q ktrain"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Cdk5lPu3bxze"
      },
      "source": [
        "### Load a Dataset Into Arrays"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "znNwcsbkQIat"
      },
      "outputs": [],
      "source": [
        "import pandas as pd\n",
        "from sklearn.model_selection import train_test_split\n",
        "from bs4 import BeautifulSoup\n",
        "import numpy as np\n",
        "\n",
        "\n",
        "def clean_reviews(review):\n",
        "    clean_review = BeautifulSoup(review, features='lxml')\n",
        "    clean_review = clean_review.get_text().replace('\"', \"\")\n",
        "    clean_review = clean_review.replace('\\n', ' ').replace('\\r', '').replace('\\t', '')\n",
        "    clean_review = clean_review.replace('\\s{2,}', ' ')\n",
        "    return clean_review\n",
        "\n",
        "\n",
        "def load_data(file_path, year_range=[2008, 2017], usefulCount_range=[0, 10000], usefulCount_quantile=None,\n",
        "              quantiles_for_class=[0.25, 0.5, 0.75], singleCondition=None):\n",
        "    # Read CSV\n",
        "    df = pd.read_csv(file_path, encoding='utf-8')\n",
        "\n",
        "    # Remove duplicate reviews\n",
        "    df = df.drop_duplicates(subset=['review', 'condition', 'date', 'rating', 'usefulCount'])\n",
        "\n",
        "    # Get most common conditions (by review count)\n",
        "    top_conditions = list(df.groupby('condition').count().reset_index().sort_values(by='uniqueID', ascending=False)[:10]['condition'])\n",
        "    df = df.loc[df['condition'].isin(top_conditions)]\n",
        "\n",
        "    # Get single condition (if passed in)\n",
        "    if singleCondition is not None:\n",
        "        df = df.loc[df['condition']==singleCondition]\n",
        "\n",
        "    # Filter the reviews by the input year_range\n",
        "    df['date'] = pd.to_datetime(df['date'])\n",
        "    df = df.loc[(df.date.dt.year >= year_range[0]) & (df.date.dt.year <= year_range[1]), :]\n",
        "\n",
        "    # Create onehot encoding for the condition so we can use it as a feature as well\n",
        "    df = pd.concat([df, pd.get_dummies(df['condition'])], axis=1)\n",
        "\n",
        "    # Clean review text\n",
        "    df['cleanReview'] = df['review'].apply(clean_reviews)\n",
        "\n",
        "    # Create standardized usefulScoreLog column (log of usefulCount normalized to be between 0 and 1)\n",
        "    with np.errstate(divide='ignore', invalid='ignore'):\n",
        "        df['usefulScoreLog'] = np.log(df['usefulCount']) / np.max(np.log(df['usefulCount']))\n",
        "    df['usefulScoreLog'] = df['usefulScoreLog'].replace(-np.Inf, 0)\n",
        "\n",
        "    # Cap the usefulCount to create a new target variable column\n",
        "    if usefulCount_quantile is not None:\n",
        "        usefulCount_range = [0, int(df['usefulCount'].quantile(q=usefulCount_quantile))]\n",
        "    df['usefulCountCapped'] = df['usefulCount'].apply(lambda row : cap_col_val(row, usefulCount_range))\n",
        "\n",
        "    # Normalize usefulCountCapped\n",
        "    df['usefulCountCappedNormalized'] = df['usefulCountCapped'] / max(df['usefulCountCapped'])\n",
        "\n",
        "    # Create normalized rating (0 to 1) to be used as a metadata feature\n",
        "    df['ratingNormalized'] = df['rating'] / np.max(df['rating'])\n",
        "\n",
        "    # Cast the date column to be a date datatype and compute the review age (with 0 corresponding to the most recent review)\n",
        "    df['daysOld'] = (max(df['date']) - df['date']).astype('timedelta64[s]') / (60*60*24)\n",
        "\n",
        "    # Compute an age score as daysOld normalized to be between 0 and 1\n",
        "    with np.errstate(divide='ignore', invalid='ignore'):\n",
        "        df['ageScore'] = df['daysOld'] / np.max(df['daysOld'])\n",
        "    df['ageScore'] = df['ageScore'].replace(-np.Inf, 0)\n",
        "\n",
        "    # Create a usefulCountClass column to treat usefulness prediction as a classification problem\n",
        "    if quantiles_for_class is not None:\n",
        "        buckets = get_buckets(df=df, quantiles=quantiles_for_class)\n",
        "        df['usefulCountClass'] = df['usefulCount'].apply(lambda row : assign_bucket(row, buckets))\n",
        "\n",
        "    # Split data into train and val\n",
        "    train = df.sample(frac=0.75, random_state=8)\n",
        "    val = df.loc[~df['uniqueID'].isin(train['uniqueID'])]\n",
        "\n",
        "    return train, val\n",
        "\n",
        "\n",
        "\n",
        "def cap_col_val(val, usefulCount_range):\n",
        "    if val > usefulCount_range[-1]:\n",
        "        val = usefulCount_range[-1]\n",
        "    return val\n",
        "\n",
        "\n",
        "def assign_bucket(val, buckets):\n",
        "    for i, bucket in enumerate(buckets):\n",
        "        if val <= 0:\n",
        "            new_val = 0  # assigns the 0 label to predictions below 0\n",
        "        if bucket[0] <= val < bucket[1]:\n",
        "            new_val = i\n",
        "    return new_val\n",
        "\n",
        "\n",
        "def get_buckets(df, quantiles):\n",
        "    cutoffs = []\n",
        "    buckets = []\n",
        "    for i in quantiles:\n",
        "        cutoffs.append(df['usefulCount'].quantile(q=i))\n",
        "    for i in range(1, len(cutoffs)):\n",
        "        if i == 1:\n",
        "            buckets.append([0, cutoffs[i-1]])\n",
        "        buckets.append([cutoffs[i-1], cutoffs[i]])\n",
        "        if i == len(cutoffs) - 1:\n",
        "            buckets.append([cutoffs[i], np.inf])\n",
        "    if len(cutoffs)==1:\n",
        "        buckets.append([0, cutoffs[0]])\n",
        "        buckets.append([cutoffs[0], np.inf])\n",
        "    return buckets"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ErYvzTkbQMyh",
        "outputId": "0c6a645d-c5a9-4298-c59d-ffd0d81c153b"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "(27036,)\n",
            "(9012,)\n"
          ]
        }
      ],
      "source": [
        "from sklearn.utils import shuffle\n",
        "from sklearn.preprocessing import LabelBinarizer\n",
        "\n",
        "num_vals = 2\n",
        "curr_quantiles = np.array([(1/num_vals)*i for i in range(1, num_vals)])\n",
        "\n",
        "\n",
        "train, val = load_data('drugsComTrain_raw.csv', year_range=[2013, 2017], quantiles_for_class=curr_quantiles)\n",
        "train = shuffle(train)\n",
        "val = shuffle(val)\n",
        "#train = shuffle(pd.concat((train, val), axis=0))\n",
        "x_train = train['cleanReview'].values\n",
        "y_train = train['usefulCountClass'].values\n",
        "\n",
        "tr, va = load_data('drugsComTest_raw.csv', year_range=[2013, 2017], quantiles_for_class=curr_quantiles)\n",
        "test = shuffle(pd.concat((tr, va), axis=0))\n",
        "x_test = val['cleanReview'].values\n",
        "y_test = val['usefulCountClass'].values\n",
        "\n",
        "print(y_train.shape)\n",
        "print(y_test.shape)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "pe5xxVPrb4IO"
      },
      "source": [
        "## STEP 1:  Preprocess Data and Create a Transformer Model\n",
        "\n",
        "We will use [DistilBERT](https://arxiv.org/abs/1910.01108)."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "vc1qKc2SbxJk",
        "outputId": "75f7128c-eaf5-41bd-e1ca-e8e8ee1949d4"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(27036,)"
            ]
          },
          "metadata": {},
          "execution_count": 6
        }
      ],
      "source": [
        "y_train.shape"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 243
        },
        "id": "5phkVc7ZYnue",
        "outputId": "7ecf5269-971c-4e00-ade9-421e0d9d1853"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "preprocessing train...\n",
            "language: en\n",
            "train sequence lengths:\n",
            "\tmean : 95\n",
            "\t95percentile : 148\n",
            "\t99percentile : 156\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              ""
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Is Multi-Label? False\n",
            "preprocessing test...\n",
            "language: en\n",
            "test sequence lengths:\n",
            "\tmean : 96\n",
            "\t95percentile : 147\n",
            "\t99percentile : 156\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              ""
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {}
        }
      ],
      "source": [
        "import ktrain\n",
        "from ktrain import text\n",
        "MODEL_NAME = 'distilbert-base-uncased'\n",
        "t = text.Transformer(MODEL_NAME, maxlen=500, class_names=np.array([0, 1]))\n",
        "trn = t.preprocess_train(x_train, y_train)\n",
        "val = t.preprocess_test(x_test, y_test)\n",
        "model = t.get_classifier()\n",
        "learner = ktrain.get_learner(model, train_data=trn, val_data=val, batch_size=8)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "G4sGPJgOcBTd"
      },
      "source": [
        "## STEP 2:  Train the Model"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 439
        },
        "id": "BJLkkoH0NJ_I",
        "outputId": "86d5e201-8332-4fef-8695-1ac474fad29e"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "simulating training for different learning rates... this may take a few moments...\n",
            "Epoch 1/2\n",
            "3379/3379 [==============================] - 961s 280ms/step - loss: 0.6125 - accuracy: 0.6550\n",
            "Epoch 2/2\n",
            "3379/3379 [==============================] - 875s 259ms/step - loss: 139.2226 - accuracy: 0.4973\n",
            "\n",
            "\n",
            "done.\n",
            "Visually inspect loss plot and select learning rate associated with falling loss\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "needs_background": "light"
          }
        }
      ],
      "source": [
        "learner.lr_find(show_plot=True, max_epochs=2)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "c_nH_F9yYvCd",
        "outputId": "603b68c6-fb77-4652-ab73-a2f56d8901c5"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "\n",
            "begin training using onecycle policy with max lr of 5e-05...\n",
            "Epoch 1/2\n",
            "3380/3380 [==============================] - 1053s 308ms/step - loss: 0.5189 - accuracy: 0.7615 - val_loss: 0.4918 - val_accuracy: 0.7769\n",
            "Epoch 2/2\n",
            "3380/3380 [==============================] - 1045s 308ms/step - loss: 0.4554 - accuracy: 0.7972 - val_loss: 0.4644 - val_accuracy: 0.7874\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<keras.callbacks.History at 0x7f8fdc598350>"
            ]
          },
          "metadata": {},
          "execution_count": 9
        }
      ],
      "source": [
        "learner.fit_onecycle(5e-5, 2)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ho6eSo9IcI3_"
      },
      "source": [
        "## STEP 3: Evaluate and Inspect the Model"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "UvcxCvLOcOje",
        "outputId": "fc308f98-4631-4dd1-e052-d217df8c52b4"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.80      0.76      0.78      4462\n",
            "           1       0.78      0.81      0.79      4550\n",
            "\n",
            "    accuracy                           0.79      9012\n",
            "   macro avg       0.79      0.79      0.79      9012\n",
            "weighted avg       0.79      0.79      0.79      9012\n",
            "\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([[3403, 1059],\n",
              "       [ 857, 3693]])"
            ]
          },
          "metadata": {},
          "execution_count": 10
        }
      ],
      "source": [
        "learner.validate(class_names=t.get_classes())"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "yhG3fPtPcVKe"
      },
      "source": [
        "Let's examine the validation example about which we were the most wrong."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "mCABLebacTWM",
        "outputId": "622b1c87-392a-4ee1-bd88-c939ca7a244a"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "----------\n",
            "id:4426 | loss:3.96 | true:1 | pred:0)\n",
            "\n"
          ]
        }
      ],
      "source": [
        "learner.view_top_losses(n=1, preproc=t)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "pHYRBdBycfne",
        "outputId": "c692ee53-c94a-4a68-cc9a-22c976362d5c"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "I've been on Latuda for around 8 months now.  I have a Dr appointment next week and I am going to ask to switch to something else or add another med to it.  I am tired all the time.  I can barely stay awake within an hour of taking it.  I am emotionless.  Never feel better than a 5 out of 10.  Don't feel happiness.  No joy in any activities.  It's definitely good at evening you out....too good.  It has not conquered my depression.  I find it hard to focus and it is starting to effect my job.  I just want to feel happy again.\n"
          ]
        }
      ],
      "source": [
        "print(x_test[7225])"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "CcZQ6HbqdMcF"
      },
      "source": [
        "## STEP 4: Making Predictions on New Data in Deployment"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "hp8tw3Y0cnJa"
      },
      "outputs": [],
      "source": [
        "predictor = ktrain.get_predictor(learner.model, preproc=t)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "LZOeu9cDdguM",
        "outputId": "dea40424-c713-4172-ad07-9a49edd20ec1"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "1"
            ]
          },
          "metadata": {},
          "execution_count": 14
        }
      ],
      "source": [
        "predictor.predict(\"I was suffering from being a slave to my negative thoughts, making assumptions about my relationship that my partner was cheating on me or having a secret life, constantly being controlling over where things go in the house, how things should be, really severe mood swings and ridiculous anger which I would ignite a lot of arguments and have the urge to get physical and just completely lose it and not think rationally. My marriage was on the verge of failure due to my negative actions and my husband was at his breaking point. My doc prescribed me 50mg of Zoloft and I finally started it, I\\'m on week 2 and I feel incredibly calm, content and full of life again. I feel like I can handle situation in a positive manner.\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "JuMmx8f5dr45",
        "outputId": "01e008d9-d7f6-44c3-d82d-44035cac05a1"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([0.03686758, 0.96313244], dtype=float32)"
            ]
          },
          "metadata": {},
          "execution_count": 15
        }
      ],
      "source": [
        "# predicted probability scores for each category\n",
        "predictor.predict_proba(\"I was suffering from being a slave to my negative thoughts, making assumptions about my relationship that my partner was cheating on me or having a secret life, constantly being controlling over where things go in the house, how things should be, really severe mood swings and ridiculous anger which I would ignite a lot of arguments and have the urge to get physical and just completely lose it and not think rationally. My marriage was on the verge of failure due to my negative actions and my husband was at his breaking point. My doc prescribed me 50mg of Zoloft and I finally started it, I\\'m on week 2 and I feel incredibly calm, content and full of life again. I feel like I can handle situation in a positive manner.\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ldxX1mtLd3Nq",
        "outputId": "3c832439-62e2-41b3-ab9b-56f50011d1cf"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[0, 1]"
            ]
          },
          "metadata": {},
          "execution_count": 16
        }
      ],
      "source": [
        "predictor.get_classes()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9tHos7V6d8RQ"
      },
      "source": [
        "As expected, `Birth Control` is assigned the highest probability.\n",
        "\n",
        "Let's invoke the `explain` method to see which words contribute most to the classification.\n",
        "\n",
        "We will need a forked version of the **eli5** library that supportes TensorFlow Keras, so let's install it first."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "g6HjLF9dd5iZ"
      },
      "outputs": [],
      "source": [
        "!pip3 install -q git+https://github.com/amaiya/eli5@tfkeras_0_10_1\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 239
        },
        "id": "3HgZDLYUeVaM",
        "outputId": "500d1da1-d45d-4c3b-f58d-f495bfe03150"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "\n",
              "    <style>\n",
              "    table.eli5-weights tr:hover {\n",
              "        filter: brightness(85%);\n",
              "    }\n",
              "</style>\n",
              "\n",
              "\n",
              "\n",
              "    \n",
              "\n",
              "    \n",
              "\n",
              "    \n",
              "\n",
              "    \n",
              "\n",
              "    \n",
              "\n",
              "    \n",
              "\n",
              "\n",
              "    \n",
              "\n",
              "    \n",
              "\n",
              "    \n",
              "\n",
              "    \n",
              "        \n",
              "\n",
              "    \n",
              "\n",
              "        \n",
              "\n",
              "        \n",
              "    \n",
              "        \n",
              "        \n",
              "    \n",
              "        <p style=\"margin-bottom: 0.5em; margin-top: 0em\">\n",
              "            <b>\n",
              "    \n",
              "        y=1\n",
              "    \n",
              "</b>\n",
              "\n",
              "    \n",
              "    (probability <b>0.947</b>, score <b>2.884</b>)\n",
              "\n",
              "top features\n",
              "        </p>\n",
              "    \n",
              "    <table class=\"eli5-weights\"\n",
              "           style=\"border-collapse: collapse; border: none; margin-top: 0em; table-layout: auto; margin-bottom: 2em;\">\n",
              "        <thead>\n",
              "        <tr style=\"border: none;\">\n",
              "            \n",
              "                <th style=\"padding: 0 1em 0 0.5em; text-align: right; border: none;\" title=\"Feature contribution already accounts for the feature value (for linear models, contribution = weight * feature value), and the sum of feature contributions is equal to the score or, for some classifiers, to the probability. Feature values are shown if &quot;show_feature_values&quot; is True.\">\n",
              "                    Contribution<sup>?</sup>\n",
              "                </th>\n",
              "            \n",
              "            <th style=\"padding: 0 0.5em 0 0.5em; text-align: left; border: none;\">Feature</th>\n",
              "            \n",
              "        </tr>\n",
              "        </thead>\n",
              "        <tbody>\n",
              "        \n",
              "            <tr style=\"background-color: hsl(120, 100.00%, 80.00%); border: none;\">\n",
              "    <td style=\"padding: 0 1em 0 0.5em; text-align: right; border: none;\">\n",
              "        +3.213\n",
              "    </td>\n",
              "    <td style=\"padding: 0 0.5em 0 0.5em; text-align: left; border: none;\">\n",
              "        Highlighted in text (sum)\n",
              "    </td>\n",
              "    \n",
              "</tr>\n",
              "        \n",
              "        \n",
              "\n",
              "        \n",
              "        \n",
              "            <tr style=\"background-color: hsl(0, 100.00%, 95.94%); border: none;\">\n",
              "    <td style=\"padding: 0 1em 0 0.5em; text-align: right; border: none;\">\n",
              "        -0.329\n",
              "    </td>\n",
              "    <td style=\"padding: 0 0.5em 0 0.5em; text-align: left; border: none;\">\n",
              "        &lt;BIAS&gt;\n",
              "    </td>\n",
              "    \n",
              "</tr>\n",
              "        \n",
              "\n",
              "        </tbody>\n",
              "    </table>\n",
              "\n",
              "    \n",
              "\n",
              "\n",
              "\n",
              "    <p style=\"margin-bottom: 2.5em; margin-top:-0.5em;\">\n",
              "        <span style=\"background-color: hsl(0, 100.00%, 94.02%); opacity: 0.81\" title=\"-0.096\">i</span><span style=\"opacity: 0.80\"> </span><span style=\"background-color: hsl(0, 100.00%, 96.07%); opacity: 0.81\" title=\"-0.053\">was</span><span style=\"opacity: 0.80\"> </span><span style=\"background-color: hsl(120, 100.00%, 90.90%); opacity: 0.82\" title=\"0.174\">suffering</span><span style=\"opacity: 0.80\"> </span><span style=\"background-color: hsl(0, 100.00%, 96.01%); opacity: 0.81\" title=\"-0.054\">from</span><span style=\"opacity: 0.80\"> </span><span style=\"background-color: hsl(120, 100.00%, 98.61%); opacity: 0.80\" title=\"0.012\">being</span><span style=\"opacity: 0.80\"> </span><span style=\"background-color: hsl(120, 100.00%, 98.83%); opacity: 0.80\" title=\"0.009\">a</span><span style=\"opacity: 0.80\"> slave </span><span style=\"background-color: hsl(120, 100.00%, 96.12%); opacity: 0.81\" title=\"0.052\">to</span><span style=\"opacity: 0.80\"> </span><span style=\"background-color: hsl(0, 100.00%, 98.12%); opacity: 0.80\" title=\"-0.018\">my</span><span style=\"opacity: 0.80\"> </span><span style=\"background-color: hsl(120, 100.00%, 93.39%); opacity: 0.82\" title=\"0.110\">negative</span><span style=\"opacity: 0.80\"> </span><span style=\"background-color: hsl(120, 100.00%, 91.74%); opacity: 0.82\" title=\"0.152\">thoughts</span><span style=\"opacity: 0.80\">, </span><span style=\"background-color: hsl(120, 100.00%, 94.74%); opacity: 0.81\" title=\"0.080\">making</span><span style=\"opacity: 0.80\"> </span><span style=\"background-color: hsl(120, 100.00%, 95.88%); opacity: 0.81\" title=\"0.056\">assumptions</span><span style=\"opacity: 0.80\"> </span><span style=\"background-color: hsl(0, 100.00%, 89.67%); opacity: 0.83\" title=\"-0.209\">about</span><span style=\"opacity: 0.80\"> </span><span style=\"background-color: hsl(0, 100.00%, 90.91%); opacity: 0.82\" title=\"-0.174\">my</span><span style=\"opacity: 0.80\"> </span><span style=\"background-color: hsl(0, 100.00%, 94.86%); opacity: 0.81\" title=\"-0.077\">relationship</span><span style=\"opacity: 0.80\"> </span><span style=\"background-color: hsl(0, 100.00%, 94.62%); opacity: 0.81\" title=\"-0.082\">that</span><span style=\"opacity: 0.80\"> </span><span style=\"background-color: hsl(0, 100.00%, 94.62%); opacity: 0.81\" title=\"-0.082\">my</span><span style=\"opacity: 0.80\"> </span><span style=\"background-color: hsl(0, 100.00%, 94.03%); opacity: 0.81\" title=\"-0.095\">partner</span><span style=\"opacity: 0.80\"> </span><span style=\"background-color: hsl(0, 100.00%, 90.95%); opacity: 0.82\" title=\"-0.173\">was</span><span style=\"opacity: 0.80\"> </span><span style=\"background-color: hsl(0, 100.00%, 91.36%); opacity: 0.82\" title=\"-0.162\">cheating</span><span style=\"opacity: 0.80\"> </span><span style=\"background-color: hsl(0, 100.00%, 96.01%); opacity: 0.81\" title=\"-0.054\">on</span><span style=\"opacity: 0.80\"> </span><span style=\"background-color: hsl(0, 100.00%, 92.39%); opacity: 0.82\" title=\"-0.135\">me</span><span style=\"opacity: 0.80\"> </span><span style=\"background-color: hsl(120, 100.00%, 98.53%); opacity: 0.80\" title=\"0.013\">or</span><span style=\"opacity: 0.80\"> </span><span style=\"background-color: hsl(120, 100.00%, 95.69%); opacity: 0.81\" title=\"0.060\">having</span><span style=\"opacity: 0.80\"> </span><span style=\"background-color: hsl(120, 100.00%, 98.83%); opacity: 0.80\" title=\"0.009\">a</span><span style=\"opacity: 0.80\"> </span><span style=\"background-color: hsl(120, 100.00%, 93.37%); opacity: 0.82\" title=\"0.111\">secret</span><span style=\"opacity: 0.80\"> </span><span style=\"background-color: hsl(120, 100.00%, 89.18%); opacity: 0.83\" title=\"0.223\">life</span><span style=\"opacity: 0.80\">, </span><span style=\"background-color: hsl(0, 100.00%, 91.05%); opacity: 0.82\" title=\"-0.170\">constantly</span><span style=\"opacity: 0.80\"> </span><span style=\"background-color: hsl(0, 100.00%, 95.30%); opacity: 0.81\" title=\"-0.068\">being</span><span style=\"opacity: 0.80\"> </span><span style=\"background-color: hsl(0, 100.00%, 98.43%); opacity: 0.80\" title=\"-0.014\">controlling</span><span style=\"opacity: 0.80\"> </span><span style=\"background-color: hsl(0, 100.00%, 90.49%); opacity: 0.83\" title=\"-0.186\">over</span><span style=\"opacity: 0.80\"> </span><span style=\"background-color: hsl(0, 100.00%, 96.34%); opacity: 0.81\" title=\"-0.048\">where</span><span style=\"opacity: 0.80\"> </span><span style=\"background-color: hsl(0, 100.00%, 96.31%); opacity: 0.81\" title=\"-0.048\">things</span><span style=\"opacity: 0.80\"> </span><span style=\"background-color: hsl(0, 100.00%, 89.82%); opacity: 0.83\" title=\"-0.205\">go</span><span style=\"opacity: 0.80\"> </span><span style=\"background-color: hsl(0, 100.00%, 95.32%); opacity: 0.81\" title=\"-0.067\">in</span><span style=\"opacity: 0.80\"> </span><span style=\"background-color: hsl(0, 100.00%, 91.96%); opacity: 0.82\" title=\"-0.146\">the</span><span style=\"opacity: 0.80\"> </span><span style=\"background-color: hsl(0, 100.00%, 93.40%); opacity: 0.82\" title=\"-0.110\">house</span><span style=\"opacity: 0.80\">, </span><span style=\"background-color: hsl(0, 100.00%, 93.27%); opacity: 0.82\" title=\"-0.114\">how</span><span style=\"opacity: 0.80\"> </span><span style=\"background-color: hsl(120, 100.00%, 98.61%); opacity: 0.80\" title=\"0.012\">things</span><span style=\"opacity: 0.80\"> </span><span style=\"background-color: hsl(120, 100.00%, 99.00%); opacity: 0.80\" title=\"0.007\">should</span><span style=\"opacity: 0.80\"> </span><span style=\"background-color: hsl(0, 100.00%, 94.93%); opacity: 0.81\" title=\"-0.076\">be</span><span style=\"opacity: 0.80\">, </span><span style=\"background-color: hsl(0, 100.00%, 96.06%); opacity: 0.81\" title=\"-0.053\">really</span><span style=\"opacity: 0.80\"> </span><span style=\"background-color: hsl(0, 100.00%, 98.55%); opacity: 0.80\" title=\"-0.013\">severe</span><span style=\"opacity: 0.80\"> </span><span style=\"background-color: hsl(0, 100.00%, 94.48%); opacity: 0.81\" title=\"-0.086\">mood</span><span style=\"opacity: 0.80\"> swings and </span><span style=\"background-color: hsl(0, 100.00%, 96.46%); opacity: 0.81\" title=\"-0.045\">ridiculous</span><span style=\"opacity: 0.80\"> </span><span style=\"background-color: hsl(120, 100.00%, 93.77%); opacity: 0.81\" title=\"0.102\">anger</span><span style=\"opacity: 0.80\"> </span><span style=\"background-color: hsl(0, 100.00%, 94.04%); opacity: 0.81\" title=\"-0.095\">which</span><span style=\"opacity: 0.80\"> </span><span style=\"background-color: hsl(120, 100.00%, 96.62%); opacity: 0.81\" title=\"0.042\">i</span><span style=\"opacity: 0.80\"> </span><span style=\"background-color: hsl(120, 100.00%, 89.27%); opacity: 0.83\" title=\"0.221\">would</span><span style=\"opacity: 0.80\"> </span><span style=\"background-color: hsl(120, 100.00%, 91.47%); opacity: 0.82\" title=\"0.159\">ignite</span><span style=\"opacity: 0.80\"> </span><span style=\"background-color: hsl(120, 100.00%, 98.83%); opacity: 0.80\" title=\"0.009\">a</span><span style=\"opacity: 0.80\"> </span><span style=\"background-color: hsl(0, 100.00%, 98.61%); opacity: 0.80\" title=\"-0.012\">lot</span><span style=\"opacity: 0.80\"> </span><span style=\"background-color: hsl(0, 100.00%, 95.22%); opacity: 0.81\" title=\"-0.069\">of</span><span style=\"opacity: 0.80\"> </span><span style=\"background-color: hsl(0, 100.00%, 93.86%); opacity: 0.81\" title=\"-0.099\">arguments</span><span style=\"opacity: 0.80\"> and </span><span style=\"background-color: hsl(0, 100.00%, 94.82%); opacity: 0.81\" title=\"-0.078\">have</span><span style=\"opacity: 0.80\"> </span><span style=\"background-color: hsl(120, 100.00%, 97.03%); opacity: 0.80\" title=\"0.035\">the</span><span style=\"opacity: 0.80\"> </span><span style=\"background-color: hsl(120, 100.00%, 94.80%); opacity: 0.81\" title=\"0.079\">urge</span><span style=\"opacity: 0.80\"> </span><span style=\"background-color: hsl(0, 100.00%, 96.85%); opacity: 0.81\" title=\"-0.038\">to</span><span style=\"opacity: 0.80\"> </span><span style=\"background-color: hsl(0, 100.00%, 94.11%); opacity: 0.81\" title=\"-0.094\">get</span><span style=\"opacity: 0.80\"> </span><span style=\"background-color: hsl(0, 100.00%, 96.46%); opacity: 0.81\" title=\"-0.045\">physical</span><span style=\"opacity: 0.80\"> </span><span style=\"background-color: hsl(0, 100.00%, 93.59%); opacity: 0.81\" title=\"-0.106\">and</span><span style=\"opacity: 0.80\"> </span><span style=\"background-color: hsl(0, 100.00%, 94.58%); opacity: 0.81\" title=\"-0.083\">just</span><span style=\"opacity: 0.80\"> </span><span style=\"background-color: hsl(0, 100.00%, 94.90%); opacity: 0.81\" title=\"-0.076\">completely</span><span style=\"opacity: 0.80\"> </span><span style=\"background-color: hsl(0, 100.00%, 96.16%); opacity: 0.81\" title=\"-0.051\">lose</span><span style=\"opacity: 0.80\"> </span><span style=\"background-color: hsl(0, 100.00%, 93.48%); opacity: 0.81\" title=\"-0.108\">it</span><span style=\"opacity: 0.80\"> </span><span style=\"background-color: hsl(0, 100.00%, 92.61%); opacity: 0.82\" title=\"-0.130\">and</span><span style=\"opacity: 0.80\"> </span><span style=\"background-color: hsl(0, 100.00%, 95.77%); opacity: 0.81\" title=\"-0.058\">not</span><span style=\"opacity: 0.80\"> </span><span style=\"background-color: hsl(120, 100.00%, 92.42%); opacity: 0.82\" title=\"0.134\">think</span><span style=\"opacity: 0.80\"> </span><span style=\"background-color: hsl(0, 100.00%, 97.98%); opacity: 0.80\" title=\"-0.020\">rationally</span><span style=\"opacity: 0.80\">. </span><span style=\"background-color: hsl(0, 100.00%, 90.82%); opacity: 0.82\" title=\"-0.177\">my</span><span style=\"opacity: 0.80\"> </span><span style=\"background-color: hsl(0, 100.00%, 95.97%); opacity: 0.81\" title=\"-0.055\">marriage</span><span style=\"opacity: 0.80\"> </span><span style=\"background-color: hsl(120, 100.00%, 93.64%); opacity: 0.81\" title=\"0.105\">was</span><span style=\"opacity: 0.80\"> </span><span style=\"background-color: hsl(120, 100.00%, 97.54%); opacity: 0.80\" title=\"0.027\">on</span><span style=\"opacity: 0.80\"> </span><span style=\"background-color: hsl(0, 100.00%, 93.97%); opacity: 0.81\" title=\"-0.097\">the</span><span style=\"opacity: 0.80\"> </span><span style=\"background-color: hsl(0, 100.00%, 93.41%); opacity: 0.82\" title=\"-0.110\">verge</span><span style=\"opacity: 0.80\"> </span><span style=\"background-color: hsl(120, 100.00%, 92.64%); opacity: 0.82\" title=\"0.129\">of</span><span style=\"opacity: 0.80\"> </span><span style=\"background-color: hsl(120, 100.00%, 96.24%); opacity: 0.81\" title=\"0.049\">failure</span><span style=\"opacity: 0.80\"> </span><span style=\"background-color: hsl(0, 100.00%, 99.30%); opacity: 0.80\" title=\"-0.004\">due</span><span style=\"opacity: 0.80\"> </span><span style=\"background-color: hsl(120, 100.00%, 96.12%); opacity: 0.81\" title=\"0.052\">to</span><span style=\"opacity: 0.80\"> </span><span style=\"background-color: hsl(0, 100.00%, 98.12%); opacity: 0.80\" title=\"-0.018\">my</span><span style=\"opacity: 0.80\"> </span><span style=\"background-color: hsl(120, 100.00%, 93.39%); opacity: 0.82\" title=\"0.110\">negative</span><span style=\"opacity: 0.80\"> </span><span style=\"background-color: hsl(120, 100.00%, 94.62%); opacity: 0.81\" title=\"0.082\">actions</span><span style=\"opacity: 0.80\"> </span><span style=\"background-color: hsl(0, 100.00%, 95.73%); opacity: 0.81\" title=\"-0.059\">and</span><span style=\"opacity: 0.80\"> my </span><span style=\"background-color: hsl(120, 100.00%, 97.81%); opacity: 0.80\" title=\"0.023\">husband</span><span style=\"opacity: 0.80\"> </span><span style=\"background-color: hsl(120, 100.00%, 98.49%); opacity: 0.80\" title=\"0.013\">was</span><span style=\"opacity: 0.80\"> </span><span style=\"background-color: hsl(0, 100.00%, 95.47%); opacity: 0.81\" title=\"-0.064\">at</span><span style=\"opacity: 0.80\"> </span><span style=\"background-color: hsl(120, 100.00%, 95.41%); opacity: 0.81\" title=\"0.066\">his</span><span style=\"opacity: 0.80\"> </span><span style=\"background-color: hsl(0, 100.00%, 96.58%); opacity: 0.81\" title=\"-0.043\">breaking</span><span style=\"opacity: 0.80\"> </span><span style=\"background-color: hsl(120, 100.00%, 90.84%); opacity: 0.82\" title=\"0.176\">point</span><span style=\"opacity: 0.80\">. </span><span style=\"background-color: hsl(120, 100.00%, 95.63%); opacity: 0.81\" title=\"0.061\">my</span><span style=\"opacity: 0.80\"> </span><span style=\"background-color: hsl(0, 100.00%, 93.92%); opacity: 0.81\" title=\"-0.098\">doc</span><span style=\"opacity: 0.80\"> </span><span style=\"background-color: hsl(120, 100.00%, 98.64%); opacity: 0.80\" title=\"0.012\">prescribed</span><span style=\"opacity: 0.80\"> </span><span style=\"background-color: hsl(0, 100.00%, 98.44%); opacity: 0.80\" title=\"-0.014\">me</span><span style=\"opacity: 0.80\"> </span><span style=\"background-color: hsl(120, 100.00%, 88.03%); opacity: 0.84\" title=\"0.258\">50mg</span><span style=\"opacity: 0.80\"> </span><span style=\"background-color: hsl(0, 100.00%, 87.33%); opacity: 0.84\" title=\"-0.280\">of</span><span style=\"opacity: 0.80\"> </span><span style=\"background-color: hsl(120, 100.00%, 60.00%); opacity: 1.00\" title=\"1.447\">zoloft</span><span style=\"opacity: 0.80\"> </span><span style=\"background-color: hsl(120, 100.00%, 96.86%); opacity: 0.81\" title=\"0.038\">and</span><span style=\"opacity: 0.80\"> </span><span style=\"background-color: hsl(120, 100.00%, 94.47%); opacity: 0.81\" title=\"0.086\">i</span><span style=\"opacity: 0.80\"> </span><span style=\"background-color: hsl(120, 100.00%, 96.14%); opacity: 0.81\" title=\"0.051\">finally</span><span style=\"opacity: 0.80\"> </span><span style=\"background-color: hsl(120, 100.00%, 96.43%); opacity: 0.81\" title=\"0.046\">started</span><span style=\"opacity: 0.80\"> </span><span style=\"background-color: hsl(0, 100.00%, 98.53%); opacity: 0.80\" title=\"-0.013\">it</span><span style=\"opacity: 0.80\">, </span><span style=\"background-color: hsl(0, 100.00%, 93.19%); opacity: 0.82\" title=\"-0.115\">i</span><span style=\"opacity: 0.80\">&#x27;</span><span style=\"background-color: hsl(0, 100.00%, 92.97%); opacity: 0.82\" title=\"-0.121\">m</span><span style=\"opacity: 0.80\"> </span><span style=\"background-color: hsl(0, 100.00%, 94.27%); opacity: 0.81\" title=\"-0.090\">on</span><span style=\"opacity: 0.80\"> </span><span style=\"background-color: hsl(0, 100.00%, 89.08%); opacity: 0.83\" title=\"-0.226\">week</span><span style=\"opacity: 0.80\"> </span><span style=\"background-color: hsl(120, 100.00%, 93.55%); opacity: 0.81\" title=\"0.107\">2</span><span style=\"opacity: 0.80\"> and </span><span style=\"background-color: hsl(120, 100.00%, 97.76%); opacity: 0.80\" title=\"0.024\">i</span><span style=\"opacity: 0.80\"> </span><span style=\"background-color: hsl(120, 100.00%, 89.54%); opacity: 0.83\" title=\"0.213\">feel</span><span style=\"opacity: 0.80\"> </span><span style=\"background-color: hsl(0, 100.00%, 97.58%); opacity: 0.80\" title=\"-0.026\">incredibly</span><span style=\"opacity: 0.80\"> </span><span style=\"background-color: hsl(0, 100.00%, 97.13%); opacity: 0.80\" title=\"-0.034\">calm</span><span style=\"opacity: 0.80\">, </span><span style=\"background-color: hsl(120, 100.00%, 88.44%); opacity: 0.83\" title=\"0.246\">content</span><span style=\"opacity: 0.80\"> and </span><span style=\"background-color: hsl(120, 100.00%, 91.59%); opacity: 0.82\" title=\"0.156\">full</span><span style=\"opacity: 0.80\"> </span><span style=\"background-color: hsl(0, 100.00%, 92.06%); opacity: 0.82\" title=\"-0.144\">of</span><span style=\"opacity: 0.80\"> </span><span style=\"background-color: hsl(120, 100.00%, 88.91%); opacity: 0.83\" title=\"0.231\">life</span><span style=\"opacity: 0.80\"> </span><span style=\"background-color: hsl(120, 100.00%, 94.91%); opacity: 0.81\" title=\"0.076\">again</span><span style=\"opacity: 0.80\">. </span><span style=\"background-color: hsl(120, 100.00%, 97.76%); opacity: 0.80\" title=\"0.024\">i</span><span style=\"opacity: 0.80\"> </span><span style=\"background-color: hsl(120, 100.00%, 91.77%); opacity: 0.82\" title=\"0.151\">feel</span><span style=\"opacity: 0.80\"> </span><span style=\"background-color: hsl(0, 100.00%, 95.60%); opacity: 0.81\" title=\"-0.062\">like</span><span style=\"opacity: 0.80\"> </span><span style=\"background-color: hsl(120, 100.00%, 97.08%); opacity: 0.80\" title=\"0.034\">i</span><span style=\"opacity: 0.80\"> </span><span style=\"background-color: hsl(120, 100.00%, 95.24%); opacity: 0.81\" title=\"0.069\">can</span><span style=\"opacity: 0.80\"> </span><span style=\"background-color: hsl(120, 100.00%, 92.27%); opacity: 0.82\" title=\"0.138\">handle</span><span style=\"opacity: 0.80\"> </span><span style=\"background-color: hsl(120, 100.00%, 96.88%); opacity: 0.81\" title=\"0.038\">situation</span><span style=\"opacity: 0.80\"> </span><span style=\"background-color: hsl(120, 100.00%, 93.16%); opacity: 0.82\" title=\"0.116\">in</span><span style=\"opacity: 0.80\"> </span><span style=\"background-color: hsl(120, 100.00%, 96.71%); opacity: 0.81\" title=\"0.041\">a</span><span style=\"opacity: 0.80\"> </span><span style=\"background-color: hsl(0, 100.00%, 95.77%); opacity: 0.81\" title=\"-0.058\">positive</span><span style=\"opacity: 0.80\"> </span><span style=\"background-color: hsl(120, 100.00%, 92.18%); opacity: 0.82\" title=\"0.140\">manner</span><span style=\"opacity: 0.80\">.</span>\n",
              "    </p>\n",
              "\n",
              "\n",
              "    \n",
              "\n",
              "    \n",
              "\n",
              "    \n",
              "\n",
              "    \n",
              "\n",
              "\n",
              "    \n",
              "\n",
              "    \n",
              "\n",
              "    \n",
              "\n",
              "    \n",
              "\n",
              "    \n",
              "\n",
              "    \n",
              "\n",
              "\n",
              "    \n",
              "\n",
              "    \n",
              "\n",
              "    \n",
              "\n",
              "    \n",
              "\n",
              "    \n",
              "\n",
              "    \n",
              "\n",
              "\n",
              "\n"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "execution_count": 18
        }
      ],
      "source": [
        "predictor.explain(\"I was suffering from being a slave to my negative thoughts, making assumptions about my relationship that my partner was cheating on me or having a secret life, constantly being controlling over where things go in the house, how things should be, really severe mood swings and ridiculous anger which I would ignite a lot of arguments and have the urge to get physical and just completely lose it and not think rationally. My marriage was on the verge of failure due to my negative actions and my husband was at his breaking point. My doc prescribed me 50mg of Zoloft and I finally started it, I\\'m on week 2 and I feel incredibly calm, content and full of life again. I feel like I can handle situation in a positive manner.\")"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "predictor.explain(\"This medication was okay.\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 170
        },
        "id": "-PF2ts69yQBH",
        "outputId": "0fbdc90c-7610-45dd-b7fb-e92e4519b7e1"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "\n",
              "    <style>\n",
              "    table.eli5-weights tr:hover {\n",
              "        filter: brightness(85%);\n",
              "    }\n",
              "</style>\n",
              "\n",
              "\n",
              "\n",
              "    \n",
              "\n",
              "    \n",
              "\n",
              "    \n",
              "\n",
              "    \n",
              "\n",
              "    \n",
              "\n",
              "    \n",
              "\n",
              "\n",
              "    \n",
              "\n",
              "    \n",
              "\n",
              "    \n",
              "\n",
              "    \n",
              "        \n",
              "\n",
              "    \n",
              "\n",
              "        \n",
              "\n",
              "        \n",
              "    \n",
              "        \n",
              "        \n",
              "    \n",
              "        <p style=\"margin-bottom: 0.5em; margin-top: 0em\">\n",
              "            <b>\n",
              "    \n",
              "        y=0\n",
              "    \n",
              "</b>\n",
              "\n",
              "    \n",
              "    (probability <b>0.365</b>, score <b>0.553</b>)\n",
              "\n",
              "top features\n",
              "        </p>\n",
              "    \n",
              "    <table class=\"eli5-weights\"\n",
              "           style=\"border-collapse: collapse; border: none; margin-top: 0em; table-layout: auto; margin-bottom: 2em;\">\n",
              "        <thead>\n",
              "        <tr style=\"border: none;\">\n",
              "            \n",
              "                <th style=\"padding: 0 1em 0 0.5em; text-align: right; border: none;\" title=\"Feature contribution already accounts for the feature value (for linear models, contribution = weight * feature value), and the sum of feature contributions is equal to the score or, for some classifiers, to the probability. Feature values are shown if &quot;show_feature_values&quot; is True.\">\n",
              "                    Contribution<sup>?</sup>\n",
              "                </th>\n",
              "            \n",
              "            <th style=\"padding: 0 0.5em 0 0.5em; text-align: left; border: none;\">Feature</th>\n",
              "            \n",
              "        </tr>\n",
              "        </thead>\n",
              "        <tbody>\n",
              "        \n",
              "            <tr style=\"background-color: hsl(120, 100.00%, 90.61%); border: none;\">\n",
              "    <td style=\"padding: 0 1em 0 0.5em; text-align: right; border: none;\">\n",
              "        +0.285\n",
              "    </td>\n",
              "    <td style=\"padding: 0 0.5em 0 0.5em; text-align: left; border: none;\">\n",
              "        &lt;BIAS&gt;\n",
              "    </td>\n",
              "    \n",
              "</tr>\n",
              "        \n",
              "        \n",
              "\n",
              "        \n",
              "        \n",
              "            <tr style=\"background-color: hsl(0, 100.00%, 80.00%); border: none;\">\n",
              "    <td style=\"padding: 0 1em 0 0.5em; text-align: right; border: none;\">\n",
              "        -0.837\n",
              "    </td>\n",
              "    <td style=\"padding: 0 0.5em 0 0.5em; text-align: left; border: none;\">\n",
              "        Highlighted in text (sum)\n",
              "    </td>\n",
              "    \n",
              "</tr>\n",
              "        \n",
              "\n",
              "        </tbody>\n",
              "    </table>\n",
              "\n",
              "    \n",
              "\n",
              "\n",
              "\n",
              "    <p style=\"margin-bottom: 2.5em; margin-top:-0.5em;\">\n",
              "        <span style=\"background-color: hsl(0, 100.00%, 75.22%); opacity: 0.90\" title=\"-0.471\">this</span><span style=\"opacity: 0.80\"> </span><span style=\"background-color: hsl(0, 100.00%, 60.00%); opacity: 1.00\" title=\"-0.934\">medication</span><span style=\"opacity: 0.80\"> </span><span style=\"background-color: hsl(0, 100.00%, 62.85%); opacity: 0.98\" title=\"-0.840\">was</span><span style=\"opacity: 0.80\"> </span><span style=\"background-color: hsl(0, 100.00%, 67.84%); opacity: 0.95\" title=\"-0.684\">okay</span><span style=\"opacity: 0.80\">.</span>\n",
              "    </p>\n",
              "\n",
              "\n",
              "    \n",
              "\n",
              "    \n",
              "\n",
              "    \n",
              "\n",
              "    \n",
              "\n",
              "\n",
              "    \n",
              "\n",
              "    \n",
              "\n",
              "    \n",
              "\n",
              "    \n",
              "\n",
              "    \n",
              "\n",
              "    \n",
              "\n",
              "\n",
              "    \n",
              "\n",
              "    \n",
              "\n",
              "    \n",
              "\n",
              "    \n",
              "\n",
              "    \n",
              "\n",
              "    \n",
              "\n",
              "\n",
              "\n"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "execution_count": 19
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "predictor.explain(\"This medication was bad.\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 170
        },
        "id": "pPu5YjTmyRRt",
        "outputId": "69bd27ea-23ac-4ebd-f362-1db0fb29b66c"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "\n",
              "    <style>\n",
              "    table.eli5-weights tr:hover {\n",
              "        filter: brightness(85%);\n",
              "    }\n",
              "</style>\n",
              "\n",
              "\n",
              "\n",
              "    \n",
              "\n",
              "    \n",
              "\n",
              "    \n",
              "\n",
              "    \n",
              "\n",
              "    \n",
              "\n",
              "    \n",
              "\n",
              "\n",
              "    \n",
              "\n",
              "    \n",
              "\n",
              "    \n",
              "\n",
              "    \n",
              "        \n",
              "\n",
              "    \n",
              "\n",
              "        \n",
              "\n",
              "        \n",
              "    \n",
              "        \n",
              "        \n",
              "    \n",
              "        <p style=\"margin-bottom: 0.5em; margin-top: 0em\">\n",
              "            <b>\n",
              "    \n",
              "        y=0\n",
              "    \n",
              "</b>\n",
              "\n",
              "    \n",
              "    (probability <b>0.317</b>, score <b>0.766</b>)\n",
              "\n",
              "top features\n",
              "        </p>\n",
              "    \n",
              "    <table class=\"eli5-weights\"\n",
              "           style=\"border-collapse: collapse; border: none; margin-top: 0em; table-layout: auto; margin-bottom: 2em;\">\n",
              "        <thead>\n",
              "        <tr style=\"border: none;\">\n",
              "            \n",
              "                <th style=\"padding: 0 1em 0 0.5em; text-align: right; border: none;\" title=\"Feature contribution already accounts for the feature value (for linear models, contribution = weight * feature value), and the sum of feature contributions is equal to the score or, for some classifiers, to the probability. Feature values are shown if &quot;show_feature_values&quot; is True.\">\n",
              "                    Contribution<sup>?</sup>\n",
              "                </th>\n",
              "            \n",
              "            <th style=\"padding: 0 0.5em 0 0.5em; text-align: left; border: none;\">Feature</th>\n",
              "            \n",
              "        </tr>\n",
              "        </thead>\n",
              "        <tbody>\n",
              "        \n",
              "            <tr style=\"background-color: hsl(120, 100.00%, 91.47%); border: none;\">\n",
              "    <td style=\"padding: 0 1em 0 0.5em; text-align: right; border: none;\">\n",
              "        +0.322\n",
              "    </td>\n",
              "    <td style=\"padding: 0 0.5em 0 0.5em; text-align: left; border: none;\">\n",
              "        &lt;BIAS&gt;\n",
              "    </td>\n",
              "    \n",
              "</tr>\n",
              "        \n",
              "        \n",
              "\n",
              "        \n",
              "        \n",
              "            <tr style=\"background-color: hsl(0, 100.00%, 80.00%); border: none;\">\n",
              "    <td style=\"padding: 0 1em 0 0.5em; text-align: right; border: none;\">\n",
              "        -1.089\n",
              "    </td>\n",
              "    <td style=\"padding: 0 0.5em 0 0.5em; text-align: left; border: none;\">\n",
              "        Highlighted in text (sum)\n",
              "    </td>\n",
              "    \n",
              "</tr>\n",
              "        \n",
              "\n",
              "        </tbody>\n",
              "    </table>\n",
              "\n",
              "    \n",
              "\n",
              "\n",
              "\n",
              "    <p style=\"margin-bottom: 2.5em; margin-top:-0.5em;\">\n",
              "        <span style=\"background-color: hsl(0, 100.00%, 65.20%); opacity: 0.96\" title=\"-0.685\">this</span><span style=\"opacity: 0.80\"> </span><span style=\"background-color: hsl(0, 100.00%, 60.00%); opacity: 1.00\" title=\"-0.835\">medication</span><span style=\"opacity: 0.80\"> </span><span style=\"background-color: hsl(0, 100.00%, 67.18%); opacity: 0.95\" title=\"-0.630\">was</span><span style=\"opacity: 0.80\"> </span><span style=\"background-color: hsl(0, 100.00%, 61.11%); opacity: 0.99\" title=\"-0.802\">bad</span><span style=\"opacity: 0.80\">.</span>\n",
              "    </p>\n",
              "\n",
              "\n",
              "    \n",
              "\n",
              "    \n",
              "\n",
              "    \n",
              "\n",
              "    \n",
              "\n",
              "\n",
              "    \n",
              "\n",
              "    \n",
              "\n",
              "    \n",
              "\n",
              "    \n",
              "\n",
              "    \n",
              "\n",
              "    \n",
              "\n",
              "\n",
              "    \n",
              "\n",
              "    \n",
              "\n",
              "    \n",
              "\n",
              "    \n",
              "\n",
              "    \n",
              "\n",
              "    \n",
              "\n",
              "\n",
              "\n"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "execution_count": 20
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 170
        },
        "id": "QsLhZLOkAqQA",
        "outputId": "d6684333-c9e9-4f3d-e845-facf7689a044"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "\n",
              "    <style>\n",
              "    table.eli5-weights tr:hover {\n",
              "        filter: brightness(85%);\n",
              "    }\n",
              "</style>\n",
              "\n",
              "\n",
              "\n",
              "    \n",
              "\n",
              "    \n",
              "\n",
              "    \n",
              "\n",
              "    \n",
              "\n",
              "    \n",
              "\n",
              "    \n",
              "\n",
              "\n",
              "    \n",
              "\n",
              "    \n",
              "\n",
              "    \n",
              "\n",
              "    \n",
              "        \n",
              "\n",
              "    \n",
              "\n",
              "        \n",
              "\n",
              "        \n",
              "    \n",
              "        \n",
              "        \n",
              "    \n",
              "        <p style=\"margin-bottom: 0.5em; margin-top: 0em\">\n",
              "            <b>\n",
              "    \n",
              "        y=1\n",
              "    \n",
              "</b>\n",
              "\n",
              "    \n",
              "    (probability <b>0.881</b>, score <b>2.001</b>)\n",
              "\n",
              "top features\n",
              "        </p>\n",
              "    \n",
              "    <table class=\"eli5-weights\"\n",
              "           style=\"border-collapse: collapse; border: none; margin-top: 0em; table-layout: auto; margin-bottom: 2em;\">\n",
              "        <thead>\n",
              "        <tr style=\"border: none;\">\n",
              "            \n",
              "                <th style=\"padding: 0 1em 0 0.5em; text-align: right; border: none;\" title=\"Feature contribution already accounts for the feature value (for linear models, contribution = weight * feature value), and the sum of feature contributions is equal to the score or, for some classifiers, to the probability. Feature values are shown if &quot;show_feature_values&quot; is True.\">\n",
              "                    Contribution<sup>?</sup>\n",
              "                </th>\n",
              "            \n",
              "            <th style=\"padding: 0 0.5em 0 0.5em; text-align: left; border: none;\">Feature</th>\n",
              "            \n",
              "        </tr>\n",
              "        </thead>\n",
              "        <tbody>\n",
              "        \n",
              "            <tr style=\"background-color: hsl(120, 100.00%, 80.00%); border: none;\">\n",
              "    <td style=\"padding: 0 1em 0 0.5em; text-align: right; border: none;\">\n",
              "        +2.438\n",
              "    </td>\n",
              "    <td style=\"padding: 0 0.5em 0 0.5em; text-align: left; border: none;\">\n",
              "        Highlighted in text (sum)\n",
              "    </td>\n",
              "    \n",
              "</tr>\n",
              "        \n",
              "        \n",
              "\n",
              "        \n",
              "        \n",
              "            <tr style=\"background-color: hsl(0, 100.00%, 93.99%); border: none;\">\n",
              "    <td style=\"padding: 0 1em 0 0.5em; text-align: right; border: none;\">\n",
              "        -0.437\n",
              "    </td>\n",
              "    <td style=\"padding: 0 0.5em 0 0.5em; text-align: left; border: none;\">\n",
              "        &lt;BIAS&gt;\n",
              "    </td>\n",
              "    \n",
              "</tr>\n",
              "        \n",
              "\n",
              "        </tbody>\n",
              "    </table>\n",
              "\n",
              "    \n",
              "\n",
              "\n",
              "\n",
              "    <p style=\"margin-bottom: 2.5em; margin-top:-0.5em;\">\n",
              "        <span style=\"background-color: hsl(120, 100.00%, 76.70%); opacity: 0.89\" title=\"0.960\">this</span><span style=\"opacity: 0.80\"> </span><span style=\"background-color: hsl(120, 100.00%, 84.82%); opacity: 0.85\" title=\"0.521\">medication</span><span style=\"opacity: 0.80\"> </span><span style=\"background-color: hsl(120, 100.00%, 70.38%); opacity: 0.93\" title=\"1.353\">was</span><span style=\"opacity: 0.80\"> </span><span style=\"background-color: hsl(120, 100.00%, 60.00%); opacity: 1.00\" title=\"2.078\">great</span><span style=\"opacity: 0.80\">.</span>\n",
              "    </p>\n",
              "\n",
              "\n",
              "    \n",
              "\n",
              "    \n",
              "\n",
              "    \n",
              "\n",
              "    \n",
              "\n",
              "\n",
              "    \n",
              "\n",
              "    \n",
              "\n",
              "    \n",
              "\n",
              "    \n",
              "\n",
              "    \n",
              "\n",
              "    \n",
              "\n",
              "\n",
              "    \n",
              "\n",
              "    \n",
              "\n",
              "    \n",
              "\n",
              "    \n",
              "\n",
              "    \n",
              "\n",
              "    \n",
              "\n",
              "\n",
              "\n"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "execution_count": 21
        }
      ],
      "source": [
        "predictor.explain(\"This medication was great.\")"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#Review for belviq medication from 8-oct-14 with rating of 1 and usefulscore of 109\n",
        "\n",
        "predictor.explain(\"I took one tablet in the morning and I was fine until the afternoon. In the afternoon I had a debilitating headache and could not function. The pain spread to the back of my neck. I could hardly move. Then to top it all off, I started feeling nauseous. I lied down on the couch and stay still but I still threw up.\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 187
        },
        "id": "RHCo_6G5G8YF",
        "outputId": "c453d6e6-3117-43a2-d7ba-a858cd8918c4"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "\n",
              "    <style>\n",
              "    table.eli5-weights tr:hover {\n",
              "        filter: brightness(85%);\n",
              "    }\n",
              "</style>\n",
              "\n",
              "\n",
              "\n",
              "    \n",
              "\n",
              "    \n",
              "\n",
              "    \n",
              "\n",
              "    \n",
              "\n",
              "    \n",
              "\n",
              "    \n",
              "\n",
              "\n",
              "    \n",
              "\n",
              "    \n",
              "\n",
              "    \n",
              "\n",
              "    \n",
              "        \n",
              "\n",
              "    \n",
              "\n",
              "        \n",
              "\n",
              "        \n",
              "    \n",
              "        \n",
              "        \n",
              "    \n",
              "        <p style=\"margin-bottom: 0.5em; margin-top: 0em\">\n",
              "            <b>\n",
              "    \n",
              "        y=1\n",
              "    \n",
              "</b>\n",
              "\n",
              "    \n",
              "    (probability <b>0.669</b>, score <b>0.706</b>)\n",
              "\n",
              "top features\n",
              "        </p>\n",
              "    \n",
              "    <table class=\"eli5-weights\"\n",
              "           style=\"border-collapse: collapse; border: none; margin-top: 0em; table-layout: auto; margin-bottom: 2em;\">\n",
              "        <thead>\n",
              "        <tr style=\"border: none;\">\n",
              "            \n",
              "                <th style=\"padding: 0 1em 0 0.5em; text-align: right; border: none;\" title=\"Feature contribution already accounts for the feature value (for linear models, contribution = weight * feature value), and the sum of feature contributions is equal to the score or, for some classifiers, to the probability. Feature values are shown if &quot;show_feature_values&quot; is True.\">\n",
              "                    Contribution<sup>?</sup>\n",
              "                </th>\n",
              "            \n",
              "            <th style=\"padding: 0 0.5em 0 0.5em; text-align: left; border: none;\">Feature</th>\n",
              "            \n",
              "        </tr>\n",
              "        </thead>\n",
              "        <tbody>\n",
              "        \n",
              "            <tr style=\"background-color: hsl(120, 100.00%, 80.00%); border: none;\">\n",
              "    <td style=\"padding: 0 1em 0 0.5em; text-align: right; border: none;\">\n",
              "        +1.152\n",
              "    </td>\n",
              "    <td style=\"padding: 0 0.5em 0 0.5em; text-align: left; border: none;\">\n",
              "        Highlighted in text (sum)\n",
              "    </td>\n",
              "    \n",
              "</tr>\n",
              "        \n",
              "        \n",
              "\n",
              "        \n",
              "        \n",
              "            <tr style=\"background-color: hsl(0, 100.00%, 89.70%); border: none;\">\n",
              "    <td style=\"padding: 0 1em 0 0.5em; text-align: right; border: none;\">\n",
              "        -0.446\n",
              "    </td>\n",
              "    <td style=\"padding: 0 0.5em 0 0.5em; text-align: left; border: none;\">\n",
              "        &lt;BIAS&gt;\n",
              "    </td>\n",
              "    \n",
              "</tr>\n",
              "        \n",
              "\n",
              "        </tbody>\n",
              "    </table>\n",
              "\n",
              "    \n",
              "\n",
              "\n",
              "\n",
              "    <p style=\"margin-bottom: 2.5em; margin-top:-0.5em;\">\n",
              "        <span style=\"background-color: hsl(0, 100.00%, 89.02%); opacity: 0.83\" title=\"-0.056\">i</span><span style=\"opacity: 0.80\"> </span><span style=\"background-color: hsl(120, 100.00%, 75.55%); opacity: 0.90\" title=\"0.176\">took</span><span style=\"opacity: 0.80\"> </span><span style=\"background-color: hsl(120, 100.00%, 66.75%); opacity: 0.95\" title=\"0.274\">one</span><span style=\"opacity: 0.80\"> </span><span style=\"background-color: hsl(120, 100.00%, 61.89%); opacity: 0.99\" title=\"0.332\">tablet</span><span style=\"opacity: 0.80\"> </span><span style=\"background-color: hsl(120, 100.00%, 92.27%); opacity: 0.82\" title=\"0.034\">in</span><span style=\"opacity: 0.80\"> </span><span style=\"background-color: hsl(0, 100.00%, 95.93%); opacity: 0.81\" title=\"-0.014\">the</span><span style=\"opacity: 0.80\"> </span><span style=\"background-color: hsl(0, 100.00%, 93.02%); opacity: 0.82\" title=\"-0.029\">morning</span><span style=\"opacity: 0.80\"> </span><span style=\"background-color: hsl(120, 100.00%, 92.90%); opacity: 0.82\" title=\"0.030\">and</span><span style=\"opacity: 0.80\"> </span><span style=\"background-color: hsl(0, 100.00%, 95.85%); opacity: 0.81\" title=\"-0.014\">i</span><span style=\"opacity: 0.80\"> </span><span style=\"background-color: hsl(120, 100.00%, 79.40%); opacity: 0.88\" title=\"0.138\">was</span><span style=\"opacity: 0.80\"> </span><span style=\"background-color: hsl(120, 100.00%, 92.51%); opacity: 0.82\" title=\"0.033\">fine</span><span style=\"opacity: 0.80\"> </span><span style=\"background-color: hsl(0, 100.00%, 85.87%); opacity: 0.85\" title=\"-0.081\">until</span><span style=\"opacity: 0.80\"> </span><span style=\"background-color: hsl(120, 100.00%, 97.96%); opacity: 0.80\" title=\"0.005\">the</span><span style=\"opacity: 0.80\"> </span><span style=\"background-color: hsl(120, 100.00%, 93.73%); opacity: 0.81\" title=\"0.025\">afternoon</span><span style=\"opacity: 0.80\">. </span><span style=\"background-color: hsl(120, 100.00%, 88.54%); opacity: 0.83\" title=\"0.060\">in</span><span style=\"opacity: 0.80\"> </span><span style=\"background-color: hsl(120, 100.00%, 85.25%); opacity: 0.85\" title=\"0.086\">the</span><span style=\"opacity: 0.80\"> </span><span style=\"background-color: hsl(0, 100.00%, 88.21%); opacity: 0.83\" title=\"-0.062\">afternoon</span><span style=\"opacity: 0.80\"> </span><span style=\"background-color: hsl(120, 100.00%, 93.92%); opacity: 0.81\" title=\"0.024\">i</span><span style=\"opacity: 0.80\"> </span><span style=\"background-color: hsl(0, 100.00%, 99.37%); opacity: 0.80\" title=\"-0.001\">had</span><span style=\"opacity: 0.80\"> </span><span style=\"background-color: hsl(0, 100.00%, 96.25%); opacity: 0.81\" title=\"-0.012\">a</span><span style=\"opacity: 0.80\"> </span><span style=\"background-color: hsl(0, 100.00%, 97.57%); opacity: 0.80\" title=\"-0.007\">debilitating</span><span style=\"opacity: 0.80\"> </span><span style=\"background-color: hsl(120, 100.00%, 81.18%); opacity: 0.87\" title=\"0.121\">headache</span><span style=\"opacity: 0.80\"> </span><span style=\"background-color: hsl(120, 100.00%, 87.56%); opacity: 0.84\" title=\"0.067\">and</span><span style=\"opacity: 0.80\"> </span><span style=\"background-color: hsl(120, 100.00%, 91.36%); opacity: 0.82\" title=\"0.040\">could</span><span style=\"opacity: 0.80\"> </span><span style=\"background-color: hsl(0, 100.00%, 86.87%); opacity: 0.84\" title=\"-0.073\">not</span><span style=\"opacity: 0.80\"> </span><span style=\"background-color: hsl(120, 100.00%, 86.13%); opacity: 0.84\" title=\"0.078\">function</span><span style=\"opacity: 0.80\">. </span><span style=\"background-color: hsl(120, 100.00%, 79.61%); opacity: 0.88\" title=\"0.136\">the</span><span style=\"opacity: 0.80\"> </span><span style=\"background-color: hsl(120, 100.00%, 60.00%); opacity: 1.00\" title=\"0.356\">pain</span><span style=\"opacity: 0.80\"> </span><span style=\"background-color: hsl(0, 100.00%, 85.49%); opacity: 0.85\" title=\"-0.084\">spread</span><span style=\"opacity: 0.80\"> </span><span style=\"background-color: hsl(0, 100.00%, 82.64%); opacity: 0.86\" title=\"-0.108\">to</span><span style=\"opacity: 0.80\"> </span><span style=\"background-color: hsl(120, 100.00%, 88.51%); opacity: 0.83\" title=\"0.060\">the</span><span style=\"opacity: 0.80\"> </span><span style=\"background-color: hsl(120, 100.00%, 84.08%); opacity: 0.85\" title=\"0.096\">back</span><span style=\"opacity: 0.80\"> </span><span style=\"background-color: hsl(120, 100.00%, 79.49%); opacity: 0.88\" title=\"0.137\">of</span><span style=\"opacity: 0.80\"> </span><span style=\"background-color: hsl(120, 100.00%, 89.45%); opacity: 0.83\" title=\"0.053\">my</span><span style=\"opacity: 0.80\"> </span><span style=\"background-color: hsl(0, 100.00%, 97.75%); opacity: 0.80\" title=\"-0.006\">neck</span><span style=\"opacity: 0.80\">. </span><span style=\"background-color: hsl(120, 100.00%, 91.24%); opacity: 0.82\" title=\"0.041\">i</span><span style=\"opacity: 0.80\"> </span><span style=\"background-color: hsl(0, 100.00%, 88.79%); opacity: 0.83\" title=\"-0.058\">could</span><span style=\"opacity: 0.80\"> </span><span style=\"background-color: hsl(0, 100.00%, 97.82%); opacity: 0.80\" title=\"-0.006\">hardly</span><span style=\"opacity: 0.80\"> </span><span style=\"background-color: hsl(120, 100.00%, 86.55%); opacity: 0.84\" title=\"0.075\">move</span><span style=\"opacity: 0.80\">. </span><span style=\"background-color: hsl(120, 100.00%, 92.10%); opacity: 0.82\" title=\"0.035\">then</span><span style=\"opacity: 0.80\"> </span><span style=\"background-color: hsl(0, 100.00%, 78.13%); opacity: 0.88\" title=\"-0.150\">to</span><span style=\"opacity: 0.80\"> </span><span style=\"background-color: hsl(0, 100.00%, 89.43%); opacity: 0.83\" title=\"-0.053\">top</span><span style=\"opacity: 0.80\"> </span><span style=\"background-color: hsl(120, 100.00%, 99.12%); opacity: 0.80\" title=\"0.002\">it</span><span style=\"opacity: 0.80\"> </span><span style=\"background-color: hsl(0, 100.00%, 99.57%); opacity: 0.80\" title=\"-0.001\">all</span><span style=\"opacity: 0.80\"> </span><span style=\"background-color: hsl(0, 100.00%, 89.35%); opacity: 0.83\" title=\"-0.054\">off</span><span style=\"opacity: 0.80\">, </span><span style=\"background-color: hsl(0, 100.00%, 88.68%); opacity: 0.83\" title=\"-0.059\">i</span><span style=\"opacity: 0.80\"> </span><span style=\"background-color: hsl(120, 100.00%, 82.10%); opacity: 0.86\" title=\"0.113\">started</span><span style=\"opacity: 0.80\"> </span><span style=\"background-color: hsl(120, 100.00%, 84.26%); opacity: 0.85\" title=\"0.094\">feeling</span><span style=\"opacity: 0.80\"> </span><span style=\"background-color: hsl(0, 100.00%, 72.17%); opacity: 0.92\" title=\"-0.212\">nauseous</span><span style=\"opacity: 0.80\">. </span><span style=\"background-color: hsl(0, 100.00%, 87.31%); opacity: 0.84\" title=\"-0.069\">i</span><span style=\"opacity: 0.80\"> </span><span style=\"background-color: hsl(120, 100.00%, 98.23%); opacity: 0.80\" title=\"0.004\">lied</span><span style=\"opacity: 0.80\"> </span><span style=\"background-color: hsl(120, 100.00%, 94.80%); opacity: 0.81\" title=\"0.019\">down</span><span style=\"opacity: 0.80\"> </span><span style=\"background-color: hsl(0, 100.00%, 96.15%); opacity: 0.81\" title=\"-0.013\">on</span><span style=\"opacity: 0.80\"> </span><span style=\"background-color: hsl(0, 100.00%, 89.30%); opacity: 0.83\" title=\"-0.054\">the</span><span style=\"opacity: 0.80\"> </span><span style=\"background-color: hsl(0, 100.00%, 91.27%); opacity: 0.82\" title=\"-0.040\">couch</span><span style=\"opacity: 0.80\"> </span><span style=\"background-color: hsl(120, 100.00%, 91.47%); opacity: 0.82\" title=\"0.039\">and</span><span style=\"opacity: 0.80\"> </span><span style=\"background-color: hsl(0, 100.00%, 93.26%); opacity: 0.82\" title=\"-0.028\">stay</span><span style=\"opacity: 0.80\"> still </span><span style=\"background-color: hsl(120, 100.00%, 94.23%); opacity: 0.81\" title=\"0.022\">but</span><span style=\"opacity: 0.80\"> </span><span style=\"background-color: hsl(120, 100.00%, 85.15%); opacity: 0.85\" title=\"0.086\">i</span><span style=\"opacity: 0.80\"> </span><span style=\"background-color: hsl(120, 100.00%, 85.15%); opacity: 0.85\" title=\"0.086\">still</span><span style=\"opacity: 0.80\"> </span><span style=\"background-color: hsl(0, 100.00%, 76.43%); opacity: 0.89\" title=\"-0.167\">threw</span><span style=\"opacity: 0.80\"> </span><span style=\"background-color: hsl(0, 100.00%, 95.74%); opacity: 0.81\" title=\"-0.015\">up</span><span style=\"opacity: 0.80\">.</span>\n",
              "    </p>\n",
              "\n",
              "\n",
              "    \n",
              "\n",
              "    \n",
              "\n",
              "    \n",
              "\n",
              "    \n",
              "\n",
              "\n",
              "    \n",
              "\n",
              "    \n",
              "\n",
              "    \n",
              "\n",
              "    \n",
              "\n",
              "    \n",
              "\n",
              "    \n",
              "\n",
              "\n",
              "    \n",
              "\n",
              "    \n",
              "\n",
              "    \n",
              "\n",
              "    \n",
              "\n",
              "    \n",
              "\n",
              "    \n",
              "\n",
              "\n",
              "\n"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "execution_count": 34
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Note: this review is 12-apr-17, drug is Adipex, for Weightloss. Rating is 10. It is useful\n",
        "\n",
        "predictor.explain(\"I took Adipex for 1 year and lost 90lbs. I changed my eating habits and starting doing light exercise 3 days a week. I've been off Adipex for 3 months and haven't gained any weight back. Just stick with a healthy eating plan and you will not gain. Medications should be used as a tool if you don't change your eating habits then you can gain all the weight back. *sidenote...please stop writing reviews when you haven't taken the medication or just started the medication. The purpose of a review is to give your opinion on a product after using it for some time. Announcing that your doctor has prescribed Adipex isn't a review and it isn't helpful for people who are looking for reviews on this website..rant over.\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 239
        },
        "id": "JWLx5qNVHSSy",
        "outputId": "72d0d172-5bac-4b25-cf6a-f4a5a3e94b60"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "\n",
              "    <style>\n",
              "    table.eli5-weights tr:hover {\n",
              "        filter: brightness(85%);\n",
              "    }\n",
              "</style>\n",
              "\n",
              "\n",
              "\n",
              "    \n",
              "\n",
              "    \n",
              "\n",
              "    \n",
              "\n",
              "    \n",
              "\n",
              "    \n",
              "\n",
              "    \n",
              "\n",
              "\n",
              "    \n",
              "\n",
              "    \n",
              "\n",
              "    \n",
              "\n",
              "    \n",
              "        \n",
              "\n",
              "    \n",
              "\n",
              "        \n",
              "\n",
              "        \n",
              "    \n",
              "        \n",
              "        \n",
              "    \n",
              "        <p style=\"margin-bottom: 0.5em; margin-top: 0em\">\n",
              "            <b>\n",
              "    \n",
              "        y=1\n",
              "    \n",
              "</b>\n",
              "\n",
              "    \n",
              "    (probability <b>0.944</b>, score <b>2.817</b>)\n",
              "\n",
              "top features\n",
              "        </p>\n",
              "    \n",
              "    <table class=\"eli5-weights\"\n",
              "           style=\"border-collapse: collapse; border: none; margin-top: 0em; table-layout: auto; margin-bottom: 2em;\">\n",
              "        <thead>\n",
              "        <tr style=\"border: none;\">\n",
              "            \n",
              "                <th style=\"padding: 0 1em 0 0.5em; text-align: right; border: none;\" title=\"Feature contribution already accounts for the feature value (for linear models, contribution = weight * feature value), and the sum of feature contributions is equal to the score or, for some classifiers, to the probability. Feature values are shown if &quot;show_feature_values&quot; is True.\">\n",
              "                    Contribution<sup>?</sup>\n",
              "                </th>\n",
              "            \n",
              "            <th style=\"padding: 0 0.5em 0 0.5em; text-align: left; border: none;\">Feature</th>\n",
              "            \n",
              "        </tr>\n",
              "        </thead>\n",
              "        <tbody>\n",
              "        \n",
              "            <tr style=\"background-color: hsl(120, 100.00%, 80.00%); border: none;\">\n",
              "    <td style=\"padding: 0 1em 0 0.5em; text-align: right; border: none;\">\n",
              "        +3.077\n",
              "    </td>\n",
              "    <td style=\"padding: 0 0.5em 0 0.5em; text-align: left; border: none;\">\n",
              "        Highlighted in text (sum)\n",
              "    </td>\n",
              "    \n",
              "</tr>\n",
              "        \n",
              "        \n",
              "\n",
              "        \n",
              "        \n",
              "            <tr style=\"background-color: hsl(0, 100.00%, 96.46%); border: none;\">\n",
              "    <td style=\"padding: 0 1em 0 0.5em; text-align: right; border: none;\">\n",
              "        -0.259\n",
              "    </td>\n",
              "    <td style=\"padding: 0 0.5em 0 0.5em; text-align: left; border: none;\">\n",
              "        &lt;BIAS&gt;\n",
              "    </td>\n",
              "    \n",
              "</tr>\n",
              "        \n",
              "\n",
              "        </tbody>\n",
              "    </table>\n",
              "\n",
              "    \n",
              "\n",
              "\n",
              "\n",
              "    <p style=\"margin-bottom: 2.5em; margin-top:-0.5em;\">\n",
              "        <span style=\"background-color: hsl(120, 100.00%, 99.79%); opacity: 0.80\" title=\"0.000\">i</span><span style=\"opacity: 0.80\"> </span><span style=\"background-color: hsl(120, 100.00%, 91.47%); opacity: 0.82\" title=\"0.052\">took</span><span style=\"opacity: 0.80\"> </span><span style=\"background-color: hsl(120, 100.00%, 60.00%); opacity: 1.00\" title=\"0.476\">adipex</span><span style=\"opacity: 0.80\"> </span><span style=\"background-color: hsl(120, 100.00%, 93.47%); opacity: 0.82\" title=\"0.036\">for</span><span style=\"opacity: 0.80\"> </span><span style=\"background-color: hsl(120, 100.00%, 84.43%); opacity: 0.85\" title=\"0.124\">1</span><span style=\"opacity: 0.80\"> </span><span style=\"background-color: hsl(120, 100.00%, 91.40%); opacity: 0.82\" title=\"0.053\">year</span><span style=\"opacity: 0.80\"> </span><span style=\"background-color: hsl(0, 100.00%, 98.60%); opacity: 0.80\" title=\"-0.004\">and</span><span style=\"opacity: 0.80\"> </span><span style=\"background-color: hsl(120, 100.00%, 82.49%); opacity: 0.86\" title=\"0.146\">lost</span><span style=\"opacity: 0.80\"> </span><span style=\"background-color: hsl(120, 100.00%, 64.65%); opacity: 0.97\" title=\"0.399\">90lbs</span><span style=\"opacity: 0.80\">. </span><span style=\"background-color: hsl(120, 100.00%, 99.79%); opacity: 0.80\" title=\"0.000\">i</span><span style=\"opacity: 0.80\"> </span><span style=\"background-color: hsl(120, 100.00%, 78.53%); opacity: 0.88\" title=\"0.196\">changed</span><span style=\"opacity: 0.80\"> </span><span style=\"background-color: hsl(120, 100.00%, 78.53%); opacity: 0.88\" title=\"0.196\">my</span><span style=\"opacity: 0.80\"> </span><span style=\"background-color: hsl(120, 100.00%, 89.06%); opacity: 0.83\" title=\"0.075\">eating</span><span style=\"opacity: 0.80\"> </span><span style=\"background-color: hsl(120, 100.00%, 93.82%); opacity: 0.81\" title=\"0.033\">habits</span><span style=\"opacity: 0.80\"> </span><span style=\"background-color: hsl(120, 100.00%, 91.47%); opacity: 0.82\" title=\"0.052\">and</span><span style=\"opacity: 0.80\"> </span><span style=\"background-color: hsl(120, 100.00%, 84.29%); opacity: 0.85\" title=\"0.125\">starting</span><span style=\"opacity: 0.80\"> </span><span style=\"background-color: hsl(120, 100.00%, 79.39%); opacity: 0.88\" title=\"0.184\">doing</span><span style=\"opacity: 0.80\"> </span><span style=\"background-color: hsl(120, 100.00%, 97.17%); opacity: 0.80\" title=\"0.011\">light</span><span style=\"opacity: 0.80\"> </span><span style=\"background-color: hsl(120, 100.00%, 78.14%); opacity: 0.88\" title=\"0.201\">exercise</span><span style=\"opacity: 0.80\"> </span><span style=\"background-color: hsl(120, 100.00%, 88.89%); opacity: 0.83\" title=\"0.076\">3</span><span style=\"opacity: 0.80\"> </span><span style=\"background-color: hsl(120, 100.00%, 89.58%); opacity: 0.83\" title=\"0.070\">days</span><span style=\"opacity: 0.80\"> </span><span style=\"background-color: hsl(0, 100.00%, 90.10%); opacity: 0.83\" title=\"-0.065\">a</span><span style=\"opacity: 0.80\"> </span><span style=\"background-color: hsl(0, 100.00%, 91.13%); opacity: 0.82\" title=\"-0.055\">week</span><span style=\"opacity: 0.80\">. </span><span style=\"background-color: hsl(120, 100.00%, 99.79%); opacity: 0.80\" title=\"0.000\">i</span><span style=\"opacity: 0.80\">&#x27;</span><span style=\"background-color: hsl(0, 100.00%, 98.08%); opacity: 0.80\" title=\"-0.006\">ve</span><span style=\"opacity: 0.80\"> </span><span style=\"background-color: hsl(120, 100.00%, 95.74%); opacity: 0.81\" title=\"0.019\">been</span><span style=\"opacity: 0.80\"> </span><span style=\"background-color: hsl(0, 100.00%, 89.77%); opacity: 0.83\" title=\"-0.068\">off</span><span style=\"opacity: 0.80\"> </span><span style=\"background-color: hsl(120, 100.00%, 63.73%); opacity: 0.97\" title=\"0.414\">adipex</span><span style=\"opacity: 0.80\"> </span><span style=\"background-color: hsl(0, 100.00%, 86.59%); opacity: 0.84\" title=\"-0.100\">for</span><span style=\"opacity: 0.80\"> </span><span style=\"background-color: hsl(120, 100.00%, 89.23%); opacity: 0.83\" title=\"0.073\">3</span><span style=\"opacity: 0.80\"> </span><span style=\"background-color: hsl(120, 100.00%, 95.06%); opacity: 0.81\" title=\"0.024\">months</span><span style=\"opacity: 0.80\"> </span><span style=\"background-color: hsl(120, 100.00%, 95.57%); opacity: 0.81\" title=\"0.021\">and</span><span style=\"opacity: 0.80\"> </span><span style=\"background-color: hsl(0, 100.00%, 95.78%); opacity: 0.81\" title=\"-0.019\">haven</span><span style=\"opacity: 0.80\">&#x27;</span><span style=\"background-color: hsl(0, 100.00%, 89.79%); opacity: 0.83\" title=\"-0.068\">t</span><span style=\"opacity: 0.80\"> </span><span style=\"background-color: hsl(0, 100.00%, 82.28%); opacity: 0.86\" title=\"-0.149\">gained</span><span style=\"opacity: 0.80\"> </span><span style=\"background-color: hsl(0, 100.00%, 88.98%); opacity: 0.83\" title=\"-0.075\">any</span><span style=\"opacity: 0.80\"> </span><span style=\"background-color: hsl(0, 100.00%, 92.16%); opacity: 0.82\" title=\"-0.046\">weight</span><span style=\"opacity: 0.80\"> </span><span style=\"background-color: hsl(120, 100.00%, 89.69%); opacity: 0.83\" title=\"0.069\">back</span><span style=\"opacity: 0.80\">. </span><span style=\"background-color: hsl(120, 100.00%, 99.29%); opacity: 0.80\" title=\"0.002\">just</span><span style=\"opacity: 0.80\"> </span><span style=\"background-color: hsl(120, 100.00%, 79.67%); opacity: 0.88\" title=\"0.181\">stick</span><span style=\"opacity: 0.80\"> </span><span style=\"background-color: hsl(120, 100.00%, 83.81%); opacity: 0.85\" title=\"0.131\">with</span><span style=\"opacity: 0.80\"> </span><span style=\"background-color: hsl(120, 100.00%, 99.31%); opacity: 0.80\" title=\"0.001\">a</span><span style=\"opacity: 0.80\"> </span><span style=\"background-color: hsl(120, 100.00%, 92.97%); opacity: 0.82\" title=\"0.040\">healthy</span><span style=\"opacity: 0.80\"> eating </span><span style=\"background-color: hsl(120, 100.00%, 89.63%); opacity: 0.83\" title=\"0.069\">plan</span><span style=\"opacity: 0.80\"> </span><span style=\"background-color: hsl(120, 100.00%, 94.18%); opacity: 0.81\" title=\"0.030\">and</span><span style=\"opacity: 0.80\"> </span><span style=\"background-color: hsl(120, 100.00%, 93.22%); opacity: 0.82\" title=\"0.038\">you</span><span style=\"opacity: 0.80\"> </span><span style=\"background-color: hsl(120, 100.00%, 94.60%); opacity: 0.81\" title=\"0.027\">will</span><span style=\"opacity: 0.80\"> </span><span style=\"background-color: hsl(0, 100.00%, 84.22%); opacity: 0.85\" title=\"-0.126\">not</span><span style=\"opacity: 0.80\"> </span><span style=\"background-color: hsl(120, 100.00%, 94.34%); opacity: 0.81\" title=\"0.029\">gain</span><span style=\"opacity: 0.80\">. </span><span style=\"background-color: hsl(0, 100.00%, 89.31%); opacity: 0.83\" title=\"-0.072\">medications</span><span style=\"opacity: 0.80\"> </span><span style=\"background-color: hsl(0, 100.00%, 92.40%); opacity: 0.82\" title=\"-0.044\">should</span><span style=\"opacity: 0.80\"> </span><span style=\"background-color: hsl(120, 100.00%, 91.15%); opacity: 0.82\" title=\"0.055\">be</span><span style=\"opacity: 0.80\"> </span><span style=\"background-color: hsl(120, 100.00%, 92.31%); opacity: 0.82\" title=\"0.045\">used</span><span style=\"opacity: 0.80\"> </span><span style=\"background-color: hsl(120, 100.00%, 93.74%); opacity: 0.81\" title=\"0.034\">as</span><span style=\"opacity: 0.80\"> </span><span style=\"background-color: hsl(0, 100.00%, 87.09%); opacity: 0.84\" title=\"-0.095\">a</span><span style=\"opacity: 0.80\"> </span><span style=\"background-color: hsl(0, 100.00%, 87.45%); opacity: 0.84\" title=\"-0.091\">tool</span><span style=\"opacity: 0.80\"> </span><span style=\"background-color: hsl(0, 100.00%, 89.31%); opacity: 0.83\" title=\"-0.072\">if</span><span style=\"opacity: 0.80\"> </span><span style=\"background-color: hsl(120, 100.00%, 90.38%); opacity: 0.83\" title=\"0.062\">you</span><span style=\"opacity: 0.80\"> </span><span style=\"background-color: hsl(120, 100.00%, 92.05%); opacity: 0.82\" title=\"0.047\">don</span><span style=\"opacity: 0.80\">&#x27;</span><span style=\"background-color: hsl(120, 100.00%, 89.41%); opacity: 0.83\" title=\"0.071\">t</span><span style=\"opacity: 0.80\"> </span><span style=\"background-color: hsl(0, 100.00%, 87.74%); opacity: 0.84\" title=\"-0.088\">change</span><span style=\"opacity: 0.80\"> </span><span style=\"background-color: hsl(120, 100.00%, 91.20%); opacity: 0.82\" title=\"0.055\">your</span><span style=\"opacity: 0.80\"> </span><span style=\"background-color: hsl(120, 100.00%, 83.93%); opacity: 0.85\" title=\"0.129\">eating</span><span style=\"opacity: 0.80\"> </span><span style=\"background-color: hsl(120, 100.00%, 93.27%); opacity: 0.82\" title=\"0.037\">habits</span><span style=\"opacity: 0.80\"> then </span><span style=\"background-color: hsl(120, 100.00%, 92.82%); opacity: 0.82\" title=\"0.041\">you</span><span style=\"opacity: 0.80\"> </span><span style=\"background-color: hsl(0, 100.00%, 94.55%); opacity: 0.81\" title=\"-0.028\">can</span><span style=\"opacity: 0.80\"> </span><span style=\"background-color: hsl(120, 100.00%, 99.17%); opacity: 0.80\" title=\"0.002\">gain</span><span style=\"opacity: 0.80\"> </span><span style=\"background-color: hsl(120, 100.00%, 82.69%); opacity: 0.86\" title=\"0.144\">all</span><span style=\"opacity: 0.80\"> </span><span style=\"background-color: hsl(120, 100.00%, 87.32%); opacity: 0.84\" title=\"0.092\">the</span><span style=\"opacity: 0.80\"> </span><span style=\"background-color: hsl(120, 100.00%, 94.25%); opacity: 0.81\" title=\"0.030\">weight</span><span style=\"opacity: 0.80\"> </span><span style=\"background-color: hsl(0, 100.00%, 84.57%); opacity: 0.85\" title=\"-0.122\">back</span><span style=\"opacity: 0.80\">. *</span><span style=\"background-color: hsl(0, 100.00%, 91.00%); opacity: 0.82\" title=\"-0.057\">sidenote</span><span style=\"opacity: 0.80\">...</span><span style=\"background-color: hsl(0, 100.00%, 88.85%); opacity: 0.83\" title=\"-0.077\">please</span><span style=\"opacity: 0.80\"> </span><span style=\"background-color: hsl(0, 100.00%, 93.70%); opacity: 0.81\" title=\"-0.034\">stop</span><span style=\"opacity: 0.80\"> </span><span style=\"background-color: hsl(120, 100.00%, 81.18%); opacity: 0.87\" title=\"0.162\">writing</span><span style=\"opacity: 0.80\"> </span><span style=\"background-color: hsl(120, 100.00%, 86.57%); opacity: 0.84\" title=\"0.100\">reviews</span><span style=\"opacity: 0.80\"> </span><span style=\"background-color: hsl(0, 100.00%, 92.69%); opacity: 0.82\" title=\"-0.042\">when</span><span style=\"opacity: 0.80\"> </span><span style=\"background-color: hsl(0, 100.00%, 96.99%); opacity: 0.80\" title=\"-0.012\">you</span><span style=\"opacity: 0.80\"> </span><span style=\"background-color: hsl(120, 100.00%, 86.50%); opacity: 0.84\" title=\"0.101\">haven</span><span style=\"opacity: 0.80\">&#x27;</span><span style=\"background-color: hsl(0, 100.00%, 95.99%); opacity: 0.81\" title=\"-0.018\">t</span><span style=\"opacity: 0.80\"> </span><span style=\"background-color: hsl(120, 100.00%, 88.01%); opacity: 0.84\" title=\"0.085\">taken</span><span style=\"opacity: 0.80\"> </span><span style=\"background-color: hsl(0, 100.00%, 93.94%); opacity: 0.81\" title=\"-0.032\">the</span><span style=\"opacity: 0.80\"> </span><span style=\"background-color: hsl(0, 100.00%, 88.04%); opacity: 0.84\" title=\"-0.085\">medication</span><span style=\"opacity: 0.80\"> </span><span style=\"background-color: hsl(0, 100.00%, 86.35%); opacity: 0.84\" title=\"-0.102\">or</span><span style=\"opacity: 0.80\"> </span><span style=\"background-color: hsl(0, 100.00%, 89.85%); opacity: 0.83\" title=\"-0.067\">just</span><span style=\"opacity: 0.80\"> </span><span style=\"background-color: hsl(0, 100.00%, 95.98%); opacity: 0.81\" title=\"-0.018\">started</span><span style=\"opacity: 0.80\"> </span><span style=\"background-color: hsl(0, 100.00%, 90.51%); opacity: 0.83\" title=\"-0.061\">the</span><span style=\"opacity: 0.80\"> </span><span style=\"background-color: hsl(120, 100.00%, 86.30%); opacity: 0.84\" title=\"0.103\">medication</span><span style=\"opacity: 0.80\">. </span><span style=\"background-color: hsl(120, 100.00%, 90.87%); opacity: 0.82\" title=\"0.058\">the</span><span style=\"opacity: 0.80\"> </span><span style=\"background-color: hsl(120, 100.00%, 96.69%); opacity: 0.81\" title=\"0.014\">purpose</span><span style=\"opacity: 0.80\"> </span><span style=\"background-color: hsl(120, 100.00%, 95.61%); opacity: 0.81\" title=\"0.020\">of</span><span style=\"opacity: 0.80\"> </span><span style=\"background-color: hsl(120, 100.00%, 99.30%); opacity: 0.80\" title=\"0.001\">a</span><span style=\"opacity: 0.80\"> </span><span style=\"background-color: hsl(120, 100.00%, 89.68%); opacity: 0.83\" title=\"0.069\">review</span><span style=\"opacity: 0.80\"> </span><span style=\"background-color: hsl(120, 100.00%, 87.70%); opacity: 0.84\" title=\"0.088\">is</span><span style=\"opacity: 0.80\"> to </span><span style=\"background-color: hsl(120, 100.00%, 86.77%); opacity: 0.84\" title=\"0.098\">give</span><span style=\"opacity: 0.80\"> </span><span style=\"background-color: hsl(120, 100.00%, 98.79%); opacity: 0.80\" title=\"0.003\">your</span><span style=\"opacity: 0.80\"> </span><span style=\"background-color: hsl(120, 100.00%, 89.81%); opacity: 0.83\" title=\"0.067\">opinion</span><span style=\"opacity: 0.80\"> </span><span style=\"background-color: hsl(120, 100.00%, 88.94%); opacity: 0.83\" title=\"0.076\">on</span><span style=\"opacity: 0.80\"> </span><span style=\"background-color: hsl(120, 100.00%, 99.85%); opacity: 0.80\" title=\"0.000\">a</span><span style=\"opacity: 0.80\"> </span><span style=\"background-color: hsl(0, 100.00%, 91.08%); opacity: 0.82\" title=\"-0.056\">product</span><span style=\"opacity: 0.80\"> </span><span style=\"background-color: hsl(120, 100.00%, 88.68%); opacity: 0.83\" title=\"0.078\">after</span><span style=\"opacity: 0.80\"> </span><span style=\"background-color: hsl(120, 100.00%, 96.78%); opacity: 0.81\" title=\"0.013\">using</span><span style=\"opacity: 0.80\"> </span><span style=\"background-color: hsl(0, 100.00%, 83.93%); opacity: 0.85\" title=\"-0.129\">it</span><span style=\"opacity: 0.80\"> </span><span style=\"background-color: hsl(0, 100.00%, 89.17%); opacity: 0.83\" title=\"-0.074\">for</span><span style=\"opacity: 0.80\"> </span><span style=\"background-color: hsl(0, 100.00%, 80.75%); opacity: 0.87\" title=\"-0.167\">some</span><span style=\"opacity: 0.80\"> </span><span style=\"background-color: hsl(0, 100.00%, 86.32%); opacity: 0.84\" title=\"-0.103\">time</span><span style=\"opacity: 0.80\">. </span><span style=\"background-color: hsl(0, 100.00%, 85.53%); opacity: 0.85\" title=\"-0.111\">announcing</span><span style=\"opacity: 0.80\"> </span><span style=\"background-color: hsl(0, 100.00%, 81.65%); opacity: 0.87\" title=\"-0.156\">that</span><span style=\"opacity: 0.80\"> </span><span style=\"background-color: hsl(120, 100.00%, 82.64%); opacity: 0.86\" title=\"0.144\">your</span><span style=\"opacity: 0.80\"> </span><span style=\"background-color: hsl(120, 100.00%, 88.89%); opacity: 0.83\" title=\"0.076\">doctor</span><span style=\"opacity: 0.80\"> </span><span style=\"background-color: hsl(0, 100.00%, 79.57%); opacity: 0.88\" title=\"-0.182\">has</span><span style=\"opacity: 0.80\"> </span><span style=\"background-color: hsl(0, 100.00%, 83.28%); opacity: 0.86\" title=\"-0.137\">prescribed</span><span style=\"opacity: 0.80\"> </span><span style=\"background-color: hsl(120, 100.00%, 75.33%); opacity: 0.90\" title=\"0.239\">adipex</span><span style=\"opacity: 0.80\"> </span><span style=\"background-color: hsl(0, 100.00%, 73.08%); opacity: 0.91\" title=\"-0.270\">isn</span><span style=\"opacity: 0.80\">&#x27;</span><span style=\"background-color: hsl(0, 100.00%, 90.04%); opacity: 0.83\" title=\"-0.065\">t</span><span style=\"opacity: 0.80\"> </span><span style=\"background-color: hsl(0, 100.00%, 89.91%); opacity: 0.83\" title=\"-0.066\">a</span><span style=\"opacity: 0.80\"> </span><span style=\"background-color: hsl(0, 100.00%, 93.77%); opacity: 0.81\" title=\"-0.033\">review</span><span style=\"opacity: 0.80\"> </span><span style=\"background-color: hsl(120, 100.00%, 91.99%); opacity: 0.82\" title=\"0.048\">and</span><span style=\"opacity: 0.80\"> it </span><span style=\"background-color: hsl(0, 100.00%, 91.08%); opacity: 0.82\" title=\"-0.056\">isn</span><span style=\"opacity: 0.80\">&#x27;</span><span style=\"background-color: hsl(0, 100.00%, 85.89%); opacity: 0.85\" title=\"-0.107\">t</span><span style=\"opacity: 0.80\"> </span><span style=\"background-color: hsl(0, 100.00%, 84.39%); opacity: 0.85\" title=\"-0.124\">helpful</span><span style=\"opacity: 0.80\"> </span><span style=\"background-color: hsl(0, 100.00%, 82.20%); opacity: 0.86\" title=\"-0.150\">for</span><span style=\"opacity: 0.80\"> </span><span style=\"background-color: hsl(0, 100.00%, 91.13%); opacity: 0.82\" title=\"-0.055\">people</span><span style=\"opacity: 0.80\"> </span><span style=\"background-color: hsl(120, 100.00%, 86.74%); opacity: 0.84\" title=\"0.098\">who</span><span style=\"opacity: 0.80\"> </span><span style=\"background-color: hsl(120, 100.00%, 87.89%); opacity: 0.84\" title=\"0.086\">are</span><span style=\"opacity: 0.80\"> </span><span style=\"background-color: hsl(120, 100.00%, 80.27%); opacity: 0.87\" title=\"0.173\">looking</span><span style=\"opacity: 0.80\"> </span><span style=\"background-color: hsl(120, 100.00%, 98.93%); opacity: 0.80\" title=\"0.003\">for</span><span style=\"opacity: 0.80\"> </span><span style=\"background-color: hsl(0, 100.00%, 96.35%); opacity: 0.81\" title=\"-0.016\">reviews</span><span style=\"opacity: 0.80\"> </span><span style=\"background-color: hsl(0, 100.00%, 87.77%); opacity: 0.84\" title=\"-0.087\">on</span><span style=\"opacity: 0.80\"> </span><span style=\"background-color: hsl(0, 100.00%, 89.29%); opacity: 0.83\" title=\"-0.072\">this</span><span style=\"opacity: 0.80\"> </span><span style=\"background-color: hsl(0, 100.00%, 98.00%); opacity: 0.80\" title=\"-0.007\">website</span><span style=\"opacity: 0.80\">..</span><span style=\"background-color: hsl(120, 100.00%, 95.57%); opacity: 0.81\" title=\"0.021\">rant</span><span style=\"opacity: 0.80\"> </span><span style=\"background-color: hsl(0, 100.00%, 95.90%); opacity: 0.81\" title=\"-0.018\">over</span><span style=\"opacity: 0.80\">.</span>\n",
              "    </p>\n",
              "\n",
              "\n",
              "    \n",
              "\n",
              "    \n",
              "\n",
              "    \n",
              "\n",
              "    \n",
              "\n",
              "\n",
              "    \n",
              "\n",
              "    \n",
              "\n",
              "    \n",
              "\n",
              "    \n",
              "\n",
              "    \n",
              "\n",
              "    \n",
              "\n",
              "\n",
              "    \n",
              "\n",
              "    \n",
              "\n",
              "    \n",
              "\n",
              "    \n",
              "\n",
              "    \n",
              "\n",
              "    \n",
              "\n",
              "\n",
              "\n"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "execution_count": 32
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "predictor.explain(\"Workedad wonders!\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 170
        },
        "id": "hh3kJG5KLonT",
        "outputId": "2d110720-6202-4200-c853-7d00454f7dde"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "\n",
              "    <style>\n",
              "    table.eli5-weights tr:hover {\n",
              "        filter: brightness(85%);\n",
              "    }\n",
              "</style>\n",
              "\n",
              "\n",
              "\n",
              "    \n",
              "\n",
              "    \n",
              "\n",
              "    \n",
              "\n",
              "    \n",
              "\n",
              "    \n",
              "\n",
              "    \n",
              "\n",
              "\n",
              "    \n",
              "\n",
              "    \n",
              "\n",
              "    \n",
              "\n",
              "    \n",
              "        \n",
              "\n",
              "    \n",
              "\n",
              "        \n",
              "\n",
              "        \n",
              "    \n",
              "        \n",
              "        \n",
              "    \n",
              "        <p style=\"margin-bottom: 0.5em; margin-top: 0em\">\n",
              "            <b>\n",
              "    \n",
              "        y=0\n",
              "    \n",
              "</b>\n",
              "\n",
              "    \n",
              "    (probability <b>0.823</b>, score <b>-1.536</b>)\n",
              "\n",
              "top features\n",
              "        </p>\n",
              "    \n",
              "    <table class=\"eli5-weights\"\n",
              "           style=\"border-collapse: collapse; border: none; margin-top: 0em; table-layout: auto; margin-bottom: 2em;\">\n",
              "        <thead>\n",
              "        <tr style=\"border: none;\">\n",
              "            \n",
              "                <th style=\"padding: 0 1em 0 0.5em; text-align: right; border: none;\" title=\"Feature contribution already accounts for the feature value (for linear models, contribution = weight * feature value), and the sum of feature contributions is equal to the score or, for some classifiers, to the probability. Feature values are shown if &quot;show_feature_values&quot; is True.\">\n",
              "                    Contribution<sup>?</sup>\n",
              "                </th>\n",
              "            \n",
              "            <th style=\"padding: 0 0.5em 0 0.5em; text-align: left; border: none;\">Feature</th>\n",
              "            \n",
              "        </tr>\n",
              "        </thead>\n",
              "        <tbody>\n",
              "        \n",
              "            <tr style=\"background-color: hsl(120, 100.00%, 80.00%); border: none;\">\n",
              "    <td style=\"padding: 0 1em 0 0.5em; text-align: right; border: none;\">\n",
              "        +1.399\n",
              "    </td>\n",
              "    <td style=\"padding: 0 0.5em 0 0.5em; text-align: left; border: none;\">\n",
              "        Highlighted in text (sum)\n",
              "    </td>\n",
              "    \n",
              "</tr>\n",
              "        \n",
              "            <tr style=\"background-color: hsl(120, 100.00%, 96.07%); border: none;\">\n",
              "    <td style=\"padding: 0 1em 0 0.5em; text-align: right; border: none;\">\n",
              "        +0.137\n",
              "    </td>\n",
              "    <td style=\"padding: 0 0.5em 0 0.5em; text-align: left; border: none;\">\n",
              "        &lt;BIAS&gt;\n",
              "    </td>\n",
              "    \n",
              "</tr>\n",
              "        \n",
              "        \n",
              "\n",
              "        \n",
              "        \n",
              "\n",
              "        </tbody>\n",
              "    </table>\n",
              "\n",
              "    \n",
              "\n",
              "\n",
              "\n",
              "    <p style=\"margin-bottom: 2.5em; margin-top:-0.5em;\">\n",
              "        <span style=\"background-color: hsl(120, 100.00%, 60.00%); opacity: 1.00\" title=\"0.788\">workedad</span><span style=\"opacity: 0.80\"> </span><span style=\"background-color: hsl(120, 100.00%, 66.52%); opacity: 0.96\" title=\"0.611\">wonders</span><span style=\"opacity: 0.80\">!</span>\n",
              "    </p>\n",
              "\n",
              "\n",
              "    \n",
              "\n",
              "    \n",
              "\n",
              "    \n",
              "\n",
              "    \n",
              "\n",
              "\n",
              "    \n",
              "\n",
              "    \n",
              "\n",
              "    \n",
              "\n",
              "    \n",
              "\n",
              "    \n",
              "\n",
              "    \n",
              "\n",
              "\n",
              "    \n",
              "\n",
              "    \n",
              "\n",
              "    \n",
              "\n",
              "    \n",
              "\n",
              "    \n",
              "\n",
              "    \n",
              "\n",
              "\n",
              "\n"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "execution_count": 41
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "predictor.explain(\"Ready to try it out!\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 170
        },
        "id": "9jNSqQYUNQCe",
        "outputId": "53180581-6460-4b6d-dc91-945601949b02"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "\n",
              "    <style>\n",
              "    table.eli5-weights tr:hover {\n",
              "        filter: brightness(85%);\n",
              "    }\n",
              "</style>\n",
              "\n",
              "\n",
              "\n",
              "    \n",
              "\n",
              "    \n",
              "\n",
              "    \n",
              "\n",
              "    \n",
              "\n",
              "    \n",
              "\n",
              "    \n",
              "\n",
              "\n",
              "    \n",
              "\n",
              "    \n",
              "\n",
              "    \n",
              "\n",
              "    \n",
              "        \n",
              "\n",
              "    \n",
              "\n",
              "        \n",
              "\n",
              "        \n",
              "    \n",
              "        \n",
              "        \n",
              "    \n",
              "        <p style=\"margin-bottom: 0.5em; margin-top: 0em\">\n",
              "            <b>\n",
              "    \n",
              "        y=0\n",
              "    \n",
              "</b>\n",
              "\n",
              "    \n",
              "    (probability <b>0.713</b>, score <b>-0.908</b>)\n",
              "\n",
              "top features\n",
              "        </p>\n",
              "    \n",
              "    <table class=\"eli5-weights\"\n",
              "           style=\"border-collapse: collapse; border: none; margin-top: 0em; table-layout: auto; margin-bottom: 2em;\">\n",
              "        <thead>\n",
              "        <tr style=\"border: none;\">\n",
              "            \n",
              "                <th style=\"padding: 0 1em 0 0.5em; text-align: right; border: none;\" title=\"Feature contribution already accounts for the feature value (for linear models, contribution = weight * feature value), and the sum of feature contributions is equal to the score or, for some classifiers, to the probability. Feature values are shown if &quot;show_feature_values&quot; is True.\">\n",
              "                    Contribution<sup>?</sup>\n",
              "                </th>\n",
              "            \n",
              "            <th style=\"padding: 0 0.5em 0 0.5em; text-align: left; border: none;\">Feature</th>\n",
              "            \n",
              "        </tr>\n",
              "        </thead>\n",
              "        <tbody>\n",
              "        \n",
              "            <tr style=\"background-color: hsl(120, 100.00%, 80.00%); border: none;\">\n",
              "    <td style=\"padding: 0 1em 0 0.5em; text-align: right; border: none;\">\n",
              "        +0.617\n",
              "    </td>\n",
              "    <td style=\"padding: 0 0.5em 0 0.5em; text-align: left; border: none;\">\n",
              "        Highlighted in text (sum)\n",
              "    </td>\n",
              "    \n",
              "</tr>\n",
              "        \n",
              "            <tr style=\"background-color: hsl(120, 100.00%, 88.16%); border: none;\">\n",
              "    <td style=\"padding: 0 1em 0 0.5em; text-align: right; border: none;\">\n",
              "        +0.292\n",
              "    </td>\n",
              "    <td style=\"padding: 0 0.5em 0 0.5em; text-align: left; border: none;\">\n",
              "        &lt;BIAS&gt;\n",
              "    </td>\n",
              "    \n",
              "</tr>\n",
              "        \n",
              "        \n",
              "\n",
              "        \n",
              "        \n",
              "\n",
              "        </tbody>\n",
              "    </table>\n",
              "\n",
              "    \n",
              "\n",
              "\n",
              "\n",
              "    <p style=\"margin-bottom: 2.5em; margin-top:-0.5em;\">\n",
              "        <span style=\"background-color: hsl(120, 100.00%, 60.00%); opacity: 1.00\" title=\"0.260\">ready</span><span style=\"opacity: 0.80\"> </span><span style=\"background-color: hsl(0, 100.00%, 70.48%); opacity: 0.93\" title=\"-0.169\">to</span><span style=\"opacity: 0.80\"> </span><span style=\"background-color: hsl(0, 100.00%, 69.70%); opacity: 0.93\" title=\"-0.175\">try</span><span style=\"opacity: 0.80\"> </span><span style=\"background-color: hsl(120, 100.00%, 78.46%); opacity: 0.88\" title=\"0.108\">it</span><span style=\"opacity: 0.80\"> </span><span style=\"background-color: hsl(120, 100.00%, 67.23%); opacity: 0.95\" title=\"0.196\">out</span><span style=\"opacity: 0.80\">!</span>\n",
              "    </p>\n",
              "\n",
              "\n",
              "    \n",
              "\n",
              "    \n",
              "\n",
              "    \n",
              "\n",
              "    \n",
              "\n",
              "\n",
              "    \n",
              "\n",
              "    \n",
              "\n",
              "    \n",
              "\n",
              "    \n",
              "\n",
              "    \n",
              "\n",
              "    \n",
              "\n",
              "\n",
              "    \n",
              "\n",
              "    \n",
              "\n",
              "    \n",
              "\n",
              "    \n",
              "\n",
              "    \n",
              "\n",
              "    \n",
              "\n",
              "\n",
              "\n"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "execution_count": 42
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "predictor.explain(\"My husband is now taking this. The first week was not so bad, he even mentioned he felt somewhat better.  This is week 2, 20's.  And he still complains of his symptoms, he is extremely moody and sleeps ALL OF THE TIME!!!  And he still has more increases to do in the packet.  Can't wait for that. I want my husband back.  Needless to say I  do not recommend this drug.\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 204
        },
        "id": "wqMyb3F2OfQj",
        "outputId": "3cf5d05c-1512-4b0d-862d-ab0ccf1c15a3"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "\n",
              "    <style>\n",
              "    table.eli5-weights tr:hover {\n",
              "        filter: brightness(85%);\n",
              "    }\n",
              "</style>\n",
              "\n",
              "\n",
              "\n",
              "    \n",
              "\n",
              "    \n",
              "\n",
              "    \n",
              "\n",
              "    \n",
              "\n",
              "    \n",
              "\n",
              "    \n",
              "\n",
              "\n",
              "    \n",
              "\n",
              "    \n",
              "\n",
              "    \n",
              "\n",
              "    \n",
              "        \n",
              "\n",
              "    \n",
              "\n",
              "        \n",
              "\n",
              "        \n",
              "    \n",
              "        \n",
              "        \n",
              "    \n",
              "        <p style=\"margin-bottom: 0.5em; margin-top: 0em\">\n",
              "            <b>\n",
              "    \n",
              "        y=0\n",
              "    \n",
              "</b>\n",
              "\n",
              "    \n",
              "    (probability <b>0.846</b>, score <b>-1.706</b>)\n",
              "\n",
              "top features\n",
              "        </p>\n",
              "    \n",
              "    <table class=\"eli5-weights\"\n",
              "           style=\"border-collapse: collapse; border: none; margin-top: 0em; table-layout: auto; margin-bottom: 2em;\">\n",
              "        <thead>\n",
              "        <tr style=\"border: none;\">\n",
              "            \n",
              "                <th style=\"padding: 0 1em 0 0.5em; text-align: right; border: none;\" title=\"Feature contribution already accounts for the feature value (for linear models, contribution = weight * feature value), and the sum of feature contributions is equal to the score or, for some classifiers, to the probability. Feature values are shown if &quot;show_feature_values&quot; is True.\">\n",
              "                    Contribution<sup>?</sup>\n",
              "                </th>\n",
              "            \n",
              "            <th style=\"padding: 0 0.5em 0 0.5em; text-align: left; border: none;\">Feature</th>\n",
              "            \n",
              "        </tr>\n",
              "        </thead>\n",
              "        <tbody>\n",
              "        \n",
              "            <tr style=\"background-color: hsl(120, 100.00%, 80.00%); border: none;\">\n",
              "    <td style=\"padding: 0 1em 0 0.5em; text-align: right; border: none;\">\n",
              "        +1.268\n",
              "    </td>\n",
              "    <td style=\"padding: 0 0.5em 0 0.5em; text-align: left; border: none;\">\n",
              "        Highlighted in text (sum)\n",
              "    </td>\n",
              "    \n",
              "</tr>\n",
              "        \n",
              "            <tr style=\"background-color: hsl(120, 100.00%, 90.50%); border: none;\">\n",
              "    <td style=\"padding: 0 1em 0 0.5em; text-align: right; border: none;\">\n",
              "        +0.438\n",
              "    </td>\n",
              "    <td style=\"padding: 0 0.5em 0 0.5em; text-align: left; border: none;\">\n",
              "        &lt;BIAS&gt;\n",
              "    </td>\n",
              "    \n",
              "</tr>\n",
              "        \n",
              "        \n",
              "\n",
              "        \n",
              "        \n",
              "\n",
              "        </tbody>\n",
              "    </table>\n",
              "\n",
              "    \n",
              "\n",
              "\n",
              "\n",
              "    <p style=\"margin-bottom: 2.5em; margin-top:-0.5em;\">\n",
              "        <span style=\"opacity: 0.80\">my </span><span style=\"background-color: hsl(0, 100.00%, 94.11%); opacity: 0.81\" title=\"-0.090\">husband</span><span style=\"opacity: 0.80\"> </span><span style=\"background-color: hsl(0, 100.00%, 92.12%); opacity: 0.82\" title=\"-0.137\">is</span><span style=\"opacity: 0.80\"> now </span><span style=\"background-color: hsl(0, 100.00%, 89.85%); opacity: 0.83\" title=\"-0.197\">taking</span><span style=\"opacity: 0.80\"> </span><span style=\"background-color: hsl(120, 100.00%, 89.11%); opacity: 0.83\" title=\"0.218\">this</span><span style=\"opacity: 0.80\">. </span><span style=\"background-color: hsl(120, 100.00%, 97.61%); opacity: 0.80\" title=\"0.025\">the</span><span style=\"opacity: 0.80\"> </span><span style=\"background-color: hsl(0, 100.00%, 92.75%); opacity: 0.82\" title=\"-0.122\">first</span><span style=\"opacity: 0.80\"> </span><span style=\"background-color: hsl(120, 100.00%, 90.14%); opacity: 0.83\" title=\"0.189\">week</span><span style=\"opacity: 0.80\"> </span><span style=\"background-color: hsl(120, 100.00%, 96.73%); opacity: 0.81\" title=\"0.039\">was</span><span style=\"opacity: 0.80\"> </span><span style=\"background-color: hsl(120, 100.00%, 93.53%); opacity: 0.81\" title=\"0.103\">not</span><span style=\"opacity: 0.80\"> </span><span style=\"background-color: hsl(120, 100.00%, 94.91%); opacity: 0.81\" title=\"0.073\">so</span><span style=\"opacity: 0.80\"> </span><span style=\"background-color: hsl(0, 100.00%, 94.76%); opacity: 0.81\" title=\"-0.077\">bad</span><span style=\"opacity: 0.80\">, </span><span style=\"background-color: hsl(0, 100.00%, 96.35%); opacity: 0.81\" title=\"-0.046\">he</span><span style=\"opacity: 0.80\"> </span><span style=\"background-color: hsl(120, 100.00%, 97.47%); opacity: 0.80\" title=\"0.027\">even</span><span style=\"opacity: 0.80\"> </span><span style=\"background-color: hsl(120, 100.00%, 93.75%); opacity: 0.81\" title=\"0.099\">mentioned</span><span style=\"opacity: 0.80\"> </span><span style=\"background-color: hsl(120, 100.00%, 96.28%); opacity: 0.81\" title=\"0.047\">he</span><span style=\"opacity: 0.80\"> </span><span style=\"background-color: hsl(0, 100.00%, 95.67%); opacity: 0.81\" title=\"-0.058\">felt</span><span style=\"opacity: 0.80\"> </span><span style=\"background-color: hsl(0, 100.00%, 97.68%); opacity: 0.80\" title=\"-0.024\">somewhat</span><span style=\"opacity: 0.80\"> </span><span style=\"background-color: hsl(0, 100.00%, 94.12%); opacity: 0.81\" title=\"-0.090\">better</span><span style=\"opacity: 0.80\">. </span><span style=\"background-color: hsl(120, 100.00%, 93.21%); opacity: 0.82\" title=\"0.111\">this</span><span style=\"opacity: 0.80\"> </span><span style=\"background-color: hsl(0, 100.00%, 99.36%); opacity: 0.80\" title=\"-0.004\">is</span><span style=\"opacity: 0.80\"> </span><span style=\"background-color: hsl(120, 100.00%, 83.70%); opacity: 0.86\" title=\"0.387\">week</span><span style=\"opacity: 0.80\"> </span><span style=\"background-color: hsl(120, 100.00%, 94.54%); opacity: 0.81\" title=\"0.081\">2</span><span style=\"opacity: 0.80\">, </span><span style=\"background-color: hsl(0, 100.00%, 85.72%); opacity: 0.85\" title=\"-0.321\">20</span><span style=\"opacity: 0.80\">&#x27;</span><span style=\"background-color: hsl(0, 100.00%, 98.48%); opacity: 0.80\" title=\"-0.013\">s</span><span style=\"opacity: 0.80\">. and </span><span style=\"background-color: hsl(0, 100.00%, 96.68%); opacity: 0.81\" title=\"-0.040\">he</span><span style=\"opacity: 0.80\"> </span><span style=\"background-color: hsl(120, 100.00%, 97.85%); opacity: 0.80\" title=\"0.021\">still</span><span style=\"opacity: 0.80\"> </span><span style=\"background-color: hsl(0, 100.00%, 97.50%); opacity: 0.80\" title=\"-0.027\">complains</span><span style=\"opacity: 0.80\"> </span><span style=\"background-color: hsl(120, 100.00%, 98.71%); opacity: 0.80\" title=\"0.010\">of</span><span style=\"opacity: 0.80\"> </span><span style=\"background-color: hsl(120, 100.00%, 98.70%); opacity: 0.80\" title=\"0.010\">his</span><span style=\"opacity: 0.80\"> </span><span style=\"background-color: hsl(0, 100.00%, 89.62%); opacity: 0.83\" title=\"-0.203\">symptoms</span><span style=\"opacity: 0.80\">, </span><span style=\"background-color: hsl(120, 100.00%, 99.01%); opacity: 0.80\" title=\"0.007\">he</span><span style=\"opacity: 0.80\"> </span><span style=\"background-color: hsl(0, 100.00%, 97.89%); opacity: 0.80\" title=\"-0.021\">is</span><span style=\"opacity: 0.80\"> </span><span style=\"background-color: hsl(120, 100.00%, 96.51%); opacity: 0.81\" title=\"0.043\">extremely</span><span style=\"opacity: 0.80\"> </span><span style=\"background-color: hsl(0, 100.00%, 93.08%); opacity: 0.82\" title=\"-0.114\">moody</span><span style=\"opacity: 0.80\"> and </span><span style=\"background-color: hsl(0, 100.00%, 87.98%); opacity: 0.84\" title=\"-0.251\">sleeps</span><span style=\"opacity: 0.80\"> </span><span style=\"background-color: hsl(0, 100.00%, 94.20%); opacity: 0.81\" title=\"-0.088\">all</span><span style=\"opacity: 0.80\"> </span><span style=\"background-color: hsl(120, 100.00%, 98.71%); opacity: 0.80\" title=\"0.010\">of</span><span style=\"opacity: 0.80\"> the </span><span style=\"background-color: hsl(0, 100.00%, 92.32%); opacity: 0.82\" title=\"-0.132\">time</span><span style=\"opacity: 0.80\">!!! </span><span style=\"background-color: hsl(0, 100.00%, 94.08%); opacity: 0.81\" title=\"-0.091\">and</span><span style=\"opacity: 0.80\"> </span><span style=\"background-color: hsl(0, 100.00%, 96.68%); opacity: 0.81\" title=\"-0.040\">he</span><span style=\"opacity: 0.80\"> </span><span style=\"background-color: hsl(0, 100.00%, 96.10%); opacity: 0.81\" title=\"-0.050\">still</span><span style=\"opacity: 0.80\"> </span><span style=\"background-color: hsl(0, 100.00%, 93.74%); opacity: 0.81\" title=\"-0.099\">has</span><span style=\"opacity: 0.80\"> </span><span style=\"background-color: hsl(120, 100.00%, 97.07%); opacity: 0.80\" title=\"0.033\">more</span><span style=\"opacity: 0.80\"> </span><span style=\"background-color: hsl(120, 100.00%, 96.38%); opacity: 0.81\" title=\"0.045\">increases</span><span style=\"opacity: 0.80\"> </span><span style=\"background-color: hsl(120, 100.00%, 91.77%); opacity: 0.82\" title=\"0.146\">to</span><span style=\"opacity: 0.80\"> </span><span style=\"background-color: hsl(120, 100.00%, 92.31%); opacity: 0.82\" title=\"0.132\">do</span><span style=\"opacity: 0.80\"> </span><span style=\"background-color: hsl(0, 100.00%, 95.40%); opacity: 0.81\" title=\"-0.064\">in</span><span style=\"opacity: 0.80\"> </span><span style=\"background-color: hsl(120, 100.00%, 86.19%); opacity: 0.84\" title=\"0.306\">the</span><span style=\"opacity: 0.80\"> </span><span style=\"background-color: hsl(120, 100.00%, 79.55%); opacity: 0.88\" title=\"0.535\">packet</span><span style=\"opacity: 0.80\">. </span><span style=\"background-color: hsl(120, 100.00%, 98.07%); opacity: 0.80\" title=\"0.018\">can</span><span style=\"opacity: 0.80\">&#x27;</span><span style=\"background-color: hsl(120, 100.00%, 89.56%); opacity: 0.83\" title=\"0.205\">t</span><span style=\"opacity: 0.80\"> </span><span style=\"background-color: hsl(120, 100.00%, 93.23%); opacity: 0.82\" title=\"0.110\">wait</span><span style=\"opacity: 0.80\"> </span><span style=\"background-color: hsl(0, 100.00%, 96.74%); opacity: 0.81\" title=\"-0.039\">for</span><span style=\"opacity: 0.80\"> </span><span style=\"background-color: hsl(0, 100.00%, 99.69%); opacity: 0.80\" title=\"-0.001\">that</span><span style=\"opacity: 0.80\">. </span><span style=\"background-color: hsl(0, 100.00%, 99.90%); opacity: 0.80\" title=\"-0.000\">i</span><span style=\"opacity: 0.80\"> </span><span style=\"background-color: hsl(0, 100.00%, 95.38%); opacity: 0.81\" title=\"-0.064\">want</span><span style=\"opacity: 0.80\"> </span><span style=\"background-color: hsl(0, 100.00%, 90.13%); opacity: 0.83\" title=\"-0.189\">my</span><span style=\"opacity: 0.80\"> </span><span style=\"background-color: hsl(0, 100.00%, 93.34%); opacity: 0.82\" title=\"-0.108\">husband</span><span style=\"opacity: 0.80\"> </span><span style=\"background-color: hsl(0, 100.00%, 90.96%); opacity: 0.82\" title=\"-0.167\">back</span><span style=\"opacity: 0.80\">. </span><span style=\"background-color: hsl(120, 100.00%, 94.38%); opacity: 0.81\" title=\"0.085\">needless</span><span style=\"opacity: 0.80\"> </span><span style=\"background-color: hsl(0, 100.00%, 92.29%); opacity: 0.82\" title=\"-0.133\">to</span><span style=\"opacity: 0.80\"> </span><span style=\"background-color: hsl(0, 100.00%, 90.42%); opacity: 0.83\" title=\"-0.181\">say</span><span style=\"opacity: 0.80\"> </span><span style=\"background-color: hsl(0, 100.00%, 99.90%); opacity: 0.80\" title=\"-0.000\">i</span><span style=\"opacity: 0.80\"> </span><span style=\"background-color: hsl(120, 100.00%, 91.43%); opacity: 0.82\" title=\"0.155\">do</span><span style=\"opacity: 0.80\"> </span><span style=\"background-color: hsl(120, 100.00%, 60.00%); opacity: 1.00\" title=\"1.396\">not</span><span style=\"opacity: 0.80\"> </span><span style=\"background-color: hsl(120, 100.00%, 70.35%); opacity: 0.93\" title=\"0.910\">recommend</span><span style=\"opacity: 0.80\"> </span><span style=\"background-color: hsl(120, 100.00%, 90.92%); opacity: 0.82\" title=\"0.168\">this</span><span style=\"opacity: 0.80\"> </span><span style=\"background-color: hsl(0, 100.00%, 83.82%); opacity: 0.85\" title=\"-0.383\">drug</span><span style=\"opacity: 0.80\">.</span>\n",
              "    </p>\n",
              "\n",
              "\n",
              "    \n",
              "\n",
              "    \n",
              "\n",
              "    \n",
              "\n",
              "    \n",
              "\n",
              "\n",
              "    \n",
              "\n",
              "    \n",
              "\n",
              "    \n",
              "\n",
              "    \n",
              "\n",
              "    \n",
              "\n",
              "    \n",
              "\n",
              "\n",
              "    \n",
              "\n",
              "    \n",
              "\n",
              "    \n",
              "\n",
              "    \n",
              "\n",
              "    \n",
              "\n",
              "    \n",
              "\n",
              "\n",
              "\n"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "execution_count": 44
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Z1nzxI_Jec-5"
      },
      "outputs": [],
      "source": [
        "predictor.save('drugUsefulClassifier')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ab3rReptIMHs",
        "outputId": "57f0ac27-d6c4-4d51-81b2-bec6eb42f2ef"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "  adding: my_distilbert_predictor/ (stored 0%)\n",
            "  adding: my_distilbert_predictor/config.json (deflated 55%)\n",
            "  adding: my_distilbert_predictor/tokenizer_config.json (deflated 40%)\n",
            "  adding: my_distilbert_predictor/vocab.txt (deflated 53%)\n",
            "  adding: my_distilbert_predictor/tokenizer.json (deflated 59%)\n",
            "  adding: my_distilbert_predictor/tf_model.preproc (deflated 46%)\n",
            "  adding: my_distilbert_predictor/tf_model.h5 (deflated 8%)\n",
            "  adding: my_distilbert_predictor/special_tokens_map.json (deflated 40%)\n"
          ]
        }
      ],
      "source": [
        "!zip -r saved_keras_model.zip my_distilbert_predictor"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "6fMDJBX6IBPo"
      },
      "outputs": [],
      "source": [
        "from google.colab import files\n",
        "files.download(\"saved_keras_model.zip\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "DDEU2s03fHsw"
      },
      "outputs": [],
      "source": [
        "loaded_model = ktrain.load_predictor('/tmp/drugUsefulClassifier')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "id": "B4R1r12rgNlI",
        "outputId": "1bd96ed0-4d5d-480d-cc01-e9a2993bf204"
      },
      "outputs": [
        {
          "data": {
            "text/html": [
              ""
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "output_type": "display_data"
        },
        {
          "data": {
            "text/plain": [
              "'comp.graphics'"
            ]
          },
          "execution_count": 24,
          "metadata": {
            "tags": []
          },
          "output_type": "execute_result"
        }
      ],
      "source": [
        "loaded_model.predict('I am not sure about this medication. It is both good and bad.')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "FCJgsiUzg1wg"
      },
      "outputs": [],
      "source": [
        ""
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "collapsed_sections": [],
      "machine_shape": "hm",
      "name": "ktrain_usefulness_attention_visualization.ipynb",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}